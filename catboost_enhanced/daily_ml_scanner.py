"""
Daily ML Scanner - ç”Ÿæˆæ¯æ—¥æ©Ÿå™¨å­¸ç¿’æ¨è–¦æ¸…å–®

æ ¹æ“š CatBoost å…¨å±€æ¨¡å‹çš„é æ¸¬ï¼Œç‚ºæ¯æ—¥è¨Šè™Ÿç”Ÿæˆæ¨è–¦æ¸…å–®å’Œæ€§èƒ½èªªæ˜ã€‚

åŠŸèƒ½:
1. è¼‰å…¥ä»Šæ—¥æª¢æ¸¬åˆ°çš„è¨Šè™Ÿ (pattern detection results)
2. ç”¨ CatBoost æ¨¡å‹é æ¸¬æ¯å€‹è¨Šè™Ÿçš„å“è³ª (A/B/C/D)
3. å¾ backtest çµæœä¸­æå–è©²çµ„åˆçš„æ­·å²ç¸¾æ•ˆ
4. é¡¯ç¤ºè¨Šè™Ÿçš„ç‰¹å¾µé‡è¦æ€§è§£é‡‹
5. ç”Ÿæˆå¯è®€çš„æ—¥å¸¸æ¨è–¦å ±å‘Š (HTML + CSV)

æ¨è–¦æ¸…å–®çµæ§‹:
- è‚¡ç¥¨ä»£ç¢¼, è¨Šè™Ÿæ—¥æœŸ, Pattern, Exit Mode
- é æ¸¬å“è³ª (A/B/C/D), é æ¸¬ä¿¡å¿ƒåº¦ (æ¦‚ç‡)
- è©²çµ„åˆçš„æ­·å²å¹´åŒ–å ±é…¬%, æ­·å²å‹ç‡%, Sharpe å€¼
- Top 5 ç‰¹å¾µå°è©²è¨Šè™Ÿçš„å½±éŸ¿èªªæ˜

Usage:
    python catboost_enhanced/daily_ml_scanner.py [--output-dir ./output]

Output:
    catboost_enhanced/results/daily_scan_[YYYY-MM-DD].csv
    catboost_enhanced/results/daily_scan_[YYYY-MM-DD].html
"""

import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, date
import pickle
from tqdm import tqdm

# æ§åˆ¶ tqdm é€²åº¦æ¢å¯¬åº¦
tqdm.pandas(desc="processing")

# Add parent directory to path (to access stock/ and its subdirectories)
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.utils.logger import setup_logger
from ml_enhanced.scripts.prepare_ml_data import load_data_polars
from src.data.institutional import load_institutional_raw, compute_institutional_features
from src.ml.features import calculate_technical_indicators
from ml_enhanced.scripts.prepare_ml_data import apply_group_zscore

logger = setup_logger('daily_ml_scanner')

# é…ç½®
CATBOOST_MODEL_PATH = Path(__file__).resolve().parents[0] / 'models' / 'catboost_global.cbm'
FEATURE_INFO_PATH = Path(__file__).resolve().parents[0] / 'models' / 'catboost_feature_info.pkl'
BACKTEST_RESULTS_PATH = Path(__file__).resolve().parents[0] / 'results' / 'backtest_by_group.csv'
FEATURE_IMPORTANCE_PATH = Path(__file__).resolve().parents[0] / 'results' / 'feature_importance.csv'

RESULTS_DIR = Path(__file__).resolve().parents[0] / 'results'

try:
    from catboost import CatBoostClassifier
except ImportError:
    logger.error("âŒ CatBoost æœªå®‰è£")
    sys.exit(1)


def load_model_and_features():
    """è¼‰å…¥ CatBoost æ¨¡å‹å’Œç‰¹å¾µä¿¡æ¯"""
    logger.info("è¼‰å…¥ CatBoost æ¨¡å‹...")

    if not CATBOOST_MODEL_PATH.exists():
        logger.error(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {CATBOOST_MODEL_PATH}")
        return None, None

    try:
        model = CatBoostClassifier()
        model.load_model(str(CATBOOST_MODEL_PATH))
        logger.info("âœ“ æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None, None

    if not FEATURE_INFO_PATH.exists():
        logger.error(f"âŒ ç‰¹å¾µä¿¡æ¯ä¸å­˜åœ¨: {FEATURE_INFO_PATH}")
        return model, None

    try:
        with open(FEATURE_INFO_PATH, 'rb') as f:
            feature_info = pickle.load(f)
        logger.info(f"âœ“ ç‰¹å¾µä¿¡æ¯è¼‰å…¥æˆåŠŸ ({len(feature_info.get('feature_cols', []))} å€‹ç‰¹å¾µ)")
        return model, feature_info
    except Exception as e:
        logger.error(f"âŒ ç‰¹å¾µä¿¡æ¯è¼‰å…¥å¤±æ•—: {e}")
        return model, None


def load_feature_importance():
    """è¼‰å…¥ç‰¹å¾µé‡è¦æ€§æ’å"""
    if not FEATURE_IMPORTANCE_PATH.exists():
        logger.warning(f"âš ï¸ ç‰¹å¾µé‡è¦æ€§æª”æ¡ˆä¸å­˜åœ¨: {FEATURE_IMPORTANCE_PATH}")
        return {}

    try:
        df = pd.read_csv(FEATURE_IMPORTANCE_PATH)
        # è½‰æ›ç‚ºå­—å…¸: feature -> importance score
        importance_dict = dict(zip(df['feature'], df['importance']))
        return importance_dict
    except Exception as e:
        logger.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥ç‰¹å¾µé‡è¦æ€§: {e}")
        return {}


def load_backtest_performance():
    """è¼‰å…¥ backtest æ€§èƒ½çµæœ (æŒ‰ patternÃ—exit_mode åˆ†çµ„)"""
    if not BACKTEST_RESULTS_PATH.exists():
        logger.warning(f"âš ï¸ Backtest çµæœä¸å­˜åœ¨: {BACKTEST_RESULTS_PATH}")
        return None

    try:
        df = pd.read_csv(BACKTEST_RESULTS_PATH)
        logger.info(f"âœ“ Backtest çµæœè¼‰å…¥: {len(df)} å€‹çµ„åˆ")
        return df
    except Exception as e:
        logger.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥ backtest çµæœ: {e}")
        return None


def get_today_signals():
    """
    è¼‰å…¥ä»Šæ—¥æª¢æ¸¬åˆ°çš„è¨Šè™Ÿï¼ŒåŒ…å«é€²å ´å’Œåœæåƒ¹ä½

    é æœŸçµæ§‹:
    - sid: è‚¡ç¥¨ä»£ç¢¼
    - date: è¨Šè™Ÿæ—¥æœŸ
    - is_cup, is_htf, is_vcp: Pattern æ¨™èªŒ
    - cup_buy_price, htf_buy_price, vcp_buy_price: é€²å ´åƒ¹ä½
    - cup_stop_price, htf_stop_price, vcp_stop_price: åœæåƒ¹ä½
    - å…¶ä»–ç‰¹å¾µåˆ—
    """
    logger.info("è¼‰å…¥ä»Šæ—¥è¨Šè™Ÿ...")

    try:
        # è¼‰å…¥å¸‚å ´è³‡æ–™
        df_polars = load_data_polars()
        if df_polars is None:
            logger.error("âŒ ç„¡æ³•è¼‰å…¥å¸‚å ´è³‡æ–™")
            return None

        df = df_polars.to_pandas()
        df['date'] = pd.to_datetime(df['date'])

        # æ‰¾å‡ºæœ€æ–°æ—¥æœŸï¼ˆä»Šæ—¥ï¼‰
        latest_date = df['date'].max()
        logger.info(f"  æœ€æ–°æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')}")

        # åªä¿ç•™æœ€æ–°æ—¥æœŸçš„è³‡æ–™
        df_today = df[df['date'] == latest_date].copy()
        logger.info(f"  ä»Šæ—¥è³‡æ–™ç­†æ•¸: {len(df_today)}")

        # ç¯©é¸ä»Šæ—¥è¨Šè™Ÿ (æœ‰ä»»ä½• pattern æ¨™èªŒ)
        pattern_cols = ['is_cup', 'is_htf', 'is_vcp']

        # æª¢æŸ¥å“ªäº› pattern åˆ—å­˜åœ¨
        available_patterns = [c for c in pattern_cols if c in df_today.columns]

        if not available_patterns:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°è¨Šè™Ÿåˆ—")
            return pd.DataFrame()

        # éæ¿¾æœ‰è¨Šè™Ÿçš„è¡Œ (ä»»ä½• pattern ç‚º True)
        has_signal = df_today[available_patterns].any(axis=1)
        today_signals = df_today[has_signal].copy()

        if len(today_signals) == 0:
            logger.info("  ä»Šæ—¥ç„¡è¨Šè™Ÿ")
            return pd.DataFrame()

        logger.info(f"âœ“ æƒæåˆ° {len(today_signals)} å€‹è¨Šè™Ÿ")
        logger.info(f"  (å°‡é€²è¡Œ CatBoost è©•åˆ†å’Œéæ¿¾)")

        # æ¨™æº–åŒ–è¨Šè™Ÿè³‡æ–™
        today_signals['sid'] = today_signals['sid'].astype(str)
        today_signals['date'] = pd.to_datetime(today_signals['date'])
        today_signals['current_price'] = today_signals['close']

        # æå–é€²å ´å’Œåœæåƒ¹ä½ä¿¡æ¯
        # æ ¹æ“šå“ªå€‹ pattern ç‚º Trueï¼Œå–å°æ‡‰çš„è²·å…¥åƒ¹å’Œåœæåƒ¹
        today_signals['buy_price'] = np.nan
        today_signals['stop_price'] = np.nan
        today_signals['pattern_type'] = 'unknown'

        if 'is_cup' in available_patterns:
            cup_mask = today_signals['is_cup'] == True
            if 'cup_buy_price' in today_signals.columns:
                today_signals.loc[cup_mask, 'buy_price'] = today_signals.loc[cup_mask, 'cup_buy_price']
                today_signals.loc[cup_mask, 'stop_price'] = today_signals.loc[cup_mask, 'cup_stop_price']
                today_signals.loc[cup_mask, 'pattern_type'] = 'cup'

        if 'is_htf' in available_patterns:
            htf_mask = today_signals['is_htf'] == True
            if 'htf_buy_price' in today_signals.columns:
                today_signals.loc[htf_mask, 'buy_price'] = today_signals.loc[htf_mask, 'htf_buy_price']
                today_signals.loc[htf_mask, 'stop_price'] = today_signals.loc[htf_mask, 'htf_stop_price']
                today_signals.loc[htf_mask, 'pattern_type'] = 'htf'

        if 'is_vcp' in available_patterns:
            vcp_mask = today_signals['is_vcp'] == True
            if 'vcp_buy_price' in today_signals.columns:
                today_signals.loc[vcp_mask, 'buy_price'] = today_signals.loc[vcp_mask, 'vcp_buy_price']
                today_signals.loc[vcp_mask, 'stop_price'] = today_signals.loc[vcp_mask, 'vcp_stop_price']
                today_signals.loc[vcp_mask, 'pattern_type'] = 'vcp'

        # è¨ˆç®—è·é›¢%
        today_signals['distance_pct'] = (today_signals['buy_price'] - today_signals['current_price']) / today_signals['buy_price'] * 100
        today_signals['status'] = today_signals.apply(
            lambda row: "å·²çªç ´" if row['current_price'] >= row['buy_price'] else "ç­‰å¾…çªç ´",
            axis=1
        )

        return today_signals

    except Exception as e:
        logger.error(f"âŒ ç„¡æ³•è¼‰å…¥è¨Šè™Ÿ: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def prepare_features_for_model(signals_df):
    """
    æº–å‚™è¨Šè™Ÿç‰¹å¾µä»¥ä¾›æ¨¡å‹é æ¸¬

    éœ€è¦ç¢ºä¿ç‰¹å¾µèˆ‡è¨“ç·´æ™‚ä¸€è‡´ (z-score æ¨™æº–åŒ–ç­‰)
    """
    logger.info("æº–å‚™è¨Šè™Ÿç‰¹å¾µ...")

    if signals_df is None or signals_df.empty:
        return None

    try:
        logger.info("  [1/4] è¼‰å…¥æ©Ÿæ§‹æµç‰¹å¾µ...")
        # è¼‰å…¥æ©Ÿæ§‹æµç‰¹å¾µ
        inst_raw = load_institutional_raw()
        if inst_raw is not None and not inst_raw.empty:
            inst_feat_df = compute_institutional_features(inst_raw)
            inst_feat_df['sid'] = inst_feat_df['sid'].astype(str)
            inst_feat_df['date'] = pd.to_datetime(inst_feat_df['date'])
            signals_df = signals_df.merge(inst_feat_df, on=['sid', 'date'], how='left')
        else:
            logger.warning("âš ï¸ æ©Ÿæ§‹æµè³‡æ–™ç¼ºå¤±ï¼Œä½¿ç”¨é›¶å¡«è£œ")

        logger.info("  [2/4] è¨ˆç®—æŠ€è¡“æŒ‡æ¨™...")
        # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (ä½¿ç”¨ tqdm é€²åº¦æ¢)
        # ä¿ç•™ sid åˆ—ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨
        signals_df = signals_df.groupby('sid', group_keys=False).apply(
            calculate_technical_indicators, include_groups=False
        ).reset_index(drop=True)
        # ç¢ºä¿ sid æ˜¯åˆ—è€Œä¸æ˜¯ index
        if 'sid' not in signals_df.columns and signals_df.index.name == 'sid':
            signals_df = signals_df.reset_index()

        logger.info("  [3/4] æ·»åŠ æ©Ÿæ§‹æµæ¯”ç‡ç‰¹å¾µ...")
        # æ·»åŠ ç¼ºå¤±çš„æ©Ÿæ§‹æµæ¯”ç‡ç‰¹å¾µ
        volume_safe = signals_df['volume'].replace(0, np.nan)
        if 'foreign_net_lag1' in signals_df.columns:
            signals_df['foreign_net_to_vol_lag1'] = signals_df['foreign_net_lag1'] / volume_safe
        else:
            signals_df['foreign_net_to_vol_lag1'] = 0.0

        if 'total_net_lag1' in signals_df.columns:
            signals_df['total_net_to_vol_lag1'] = signals_df['total_net_lag1'] / volume_safe
        else:
            signals_df['total_net_to_vol_lag1'] = 0.0

        logger.info("  [4/4] ç¢ºèªåˆ†é¡ç‰¹å¾µ...")
        # pattern_type å’Œ exit_mode æ‡‰è©²å·²ç¶“åœ¨ get_today_signals() ä¸­è¨­ç½®
        # é€™è£¡åªç¢ºä¿å®ƒå€‘å­˜åœ¨
        if 'pattern_type' not in signals_df.columns:
            signals_df['pattern_type'] = 'unknown'

        if 'exit_mode' not in signals_df.columns:
            signals_df['exit_mode'] = 'fixed_r2_t20'

        # å¡«è£œ NaN å€¼ç‚º 0
        signals_df = signals_df.fillna(0)

        logger.info("âœ“ ç‰¹å¾µæº–å‚™å®Œæˆ")
        return signals_df

    except Exception as e:
        logger.error(f"âŒ ç‰¹å¾µæº–å‚™å¤±æ•—: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def predict_signal_quality(model, feature_info, signals_df):
    """
    ç”¨ CatBoost æ¨¡å‹é æ¸¬æ¯å€‹è¨Šè™Ÿçš„å“è³ª

    è¿”å›: signals_df with columns:
    - pred_label: 0-3 (D/C/B/A)
    - pred_proba_A, pred_proba_B, pred_proba_C, pred_proba_D: å„é¡åˆ¥æ¦‚ç‡
    """
    logger.info("é æ¸¬è¨Šè™Ÿå“è³ª...")

    if model is None or feature_info is None or signals_df is None or signals_df.empty:
        logger.error("âŒ æ¨¡å‹æˆ–è³‡æ–™ç¼ºå¤±")
        return None

    try:
        feature_cols = feature_info.get('feature_cols', [])
        cat_features = feature_info.get('cat_features', [])

        # é‡å»ºå®Œæ•´ç‰¹å¾µåˆ—è¡¨
        full_feature_cols = feature_cols + cat_features

        # æª¢æŸ¥ç‰¹å¾µ
        missing = [c for c in full_feature_cols if c not in signals_df.columns]
        if missing:
            logger.warning(f"âš ï¸ ç¼ºå¤±ç‰¹å¾µ: {missing}")

        # ç¯©é¸å¯ç”¨ç‰¹å¾µ (å¿…é ˆæŒ‰ç…§æ¨¡å‹æœŸæœ›çš„é †åº)
        available_features = [c for c in full_feature_cols if c in signals_df.columns]
        X = signals_df[available_features].copy()

        # å¡«è£œ NaN å€¼
        X = X.fillna(0)

        # é æ¸¬
        try:
            y_pred = model.predict(X)
            y_pred_proba = model.predict_proba(X)
        except Exception as pred_error:
            logger.error(f"âŒ CatBoost é æ¸¬å…§éƒ¨éŒ¯èª¤: {pred_error}")
            logger.warning(f"  ä½¿ç”¨ç‰¹å¾µæ•¸: {X.shape[1]}, æœŸæœ›ç‰¹å¾µæ•¸: {len(full_feature_cols)}")
            logger.warning(f"  å¯ç”¨ç‰¹å¾µ: {available_features}")
            raise

        signals_df['pred_label'] = y_pred
        label_map = {0: 'D', 1: 'C', 2: 'B', 3: 'A'}
        signals_df['pred_grade'] = signals_df['pred_label'].map(label_map)

        # æ·»åŠ æ¦‚ç‡åˆ—
        for i in range(4):
            grade = label_map[i]
            signals_df[f'pred_proba_{grade}'] = y_pred_proba[:, i]

        # çµ±è¨ˆ
        logger.info("  é æ¸¬æ¨™ç±¤åˆ†ä½ˆ:")
        for label_val in range(4):
            count = (y_pred == label_val).sum()
            pct = count / len(y_pred) * 100 if len(y_pred) > 0 else 0
            logger.info(f"    {label_map[label_val]}: {count} ({pct:.1f}%)")

        return signals_df

    except Exception as e:
        logger.error(f"âŒ é æ¸¬å¤±æ•—: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def enrich_with_backtest_performance(signals_df, backtest_df):
    """
    å°‡ backtest æ€§èƒ½æ•¸æ“šåŠ å…¥è¨Šè™Ÿåˆ—è¡¨

    æ ¹æ“š pattern å’Œ exit_mode åŒ¹é…ï¼Œæ·»åŠ æ­·å²ç¸¾æ•ˆæŒ‡æ¨™
    """
    logger.info("æ·»åŠ  Backtest æ€§èƒ½æ•¸æ“š...")

    if signals_df is None or signals_df.empty or backtest_df is None or backtest_df.empty:
        logger.warning("âš ï¸ è¨Šè™Ÿæˆ– backtest çµæœç¼ºå¤±")
        return signals_df

    # ç¢ºä¿ pattern_type å’Œ exit_mode åˆ—å­˜åœ¨
    if 'pattern_type' not in signals_df.columns or 'exit_mode' not in signals_df.columns:
        logger.warning("âš ï¸ è¨Šè™Ÿç¼ºå°‘ pattern_type æˆ– exit_mode åˆ—")
        return signals_df

    # é æœŸçš„ backtest åˆ—
    perf_cols = ['Ann. Return %', 'Win Rate', 'Sharpe', 'Max Drawdown %']
    available_perf_cols = [c for c in perf_cols if c in backtest_df.columns]

    # åˆä½µ
    try:
        signals_df = signals_df.merge(
            backtest_df[['pattern', 'exit_mode'] + available_perf_cols],
            left_on=['pattern_type', 'exit_mode'],
            right_on=['pattern', 'exit_mode'],
            how='left'
        )

        logger.info("âœ“ Backtest æ€§èƒ½æ•¸æ“šå·²æ·»åŠ ")
        return signals_df

    except Exception as e:
        logger.warning(f"âš ï¸ ç„¡æ³•åˆä½µ backtest æ•¸æ“š: {e}")
        return signals_df


def get_feature_explanation(signal_row, feature_importance, model, feature_info, top_n=5):
    """
    ç‚ºå–®å€‹è¨Šè™Ÿç”Ÿæˆç‰¹å¾µé‡è¦æ€§è§£é‡‹

    è¿”å›: list of (feature_name, importance_score, direction) çš„ top N
    """
    if not feature_importance or model is None:
        return []

    try:
        # å–æ¨¡å‹çš„ top ç‰¹å¾µ
        model_importance = model.get_feature_importance()
        feature_cols = feature_info.get('feature_cols', [])
        cat_features = feature_info.get('cat_features', [])
        all_features = feature_cols + cat_features

        # é…å°ç‰¹å¾µåç¨±å’Œé‡è¦æ€§
        feature_importance_dict = dict(zip(all_features, model_importance))

        # æ’åºä¸¦å– top N
        top_features = sorted(
            feature_importance_dict.items(),
            key=lambda x: x[1],
            reverse=True
        )[:top_n]

        explanations = []
        for feature_name, importance_score in top_features:
            if feature_name in signal_row.index:
                value = signal_row[feature_name]
                direction = "â†‘" if value > 0 else "â†“"
                explanations.append((feature_name, importance_score, direction, value))

        return explanations

    except Exception as e:
        logger.warning(f"âš ï¸ ç„¡æ³•ç”Ÿæˆç‰¹å¾µèªªæ˜: {e}")
        return []


def load_weekly_signals():
    """è¼‰å…¥éå»ä¸€é€±çš„æ¨è–¦è¨Šè™Ÿæ¸…å–®"""
    try:
        from datetime import timedelta
        today = date.today()
        week_ago = today - timedelta(days=7)

        signals = []
        for i in range(7):
            check_date = week_ago + timedelta(days=i)
            date_str = check_date.strftime('%Y-%m-%d')
            # è¼‰å…¥é€™å¤©æƒæç”Ÿæˆçš„è¨Šè™Ÿ
            md_file = RESULTS_DIR / f'catboost_daily_summary_{date_str}.md'

            # å¦‚æœ MD æª”æ¡ˆå­˜åœ¨ï¼Œå˜—è©¦è§£æï¼›å¦å‰‡å°‹æ‰¾åŸå§‹ CSV
            if md_file.exists():
                # å¾ MD å ±å‘Šä¸­æå–æ¨è–¦è¨Šè™Ÿä¿¡æ¯
                pass  # ç°¡åŒ–ï¼šç›´æ¥ä½¿ç”¨ CSV

            csv_file = RESULTS_DIR / f'daily_scan_{date_str}.csv'
            if csv_file.exists():
                df = pd.read_csv(csv_file)
                df['scan_date'] = date_str
                signals.append(df)

        if signals:
            return pd.concat(signals, ignore_index=True)
        return pd.DataFrame()
    except Exception as e:
        logger.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥ä¸€é€±è¨Šè™Ÿ: {e}")
        return pd.DataFrame()


def get_top_strategies(backtest_df, n=3):
    """å¾ backtest çµæœä¸­å–å‡º Top N ç­–ç•¥

    è¿”å›: [
        {'name': 'HTF fixed_r2_t20', 'return': 208.2, 'sharpe': 3.15, 'win_rate': 69.3,
         'mdd': 24.0, 'avg_holding': 11.5, 'max_wins': 34, 'max_losses': 23},
        ...
    ]
    """
    if backtest_df is None or backtest_df.empty:
        return []

    try:
        # æŒ‰å¹´åŒ–å ±é…¬æ’åº
        top_by_return = backtest_df.nlargest(n, 'Ann. Return %')
        strategies = []

        for _, row in top_by_return.iterrows():
            pattern = row.get('pattern', 'N/A')
            exit_mode = row.get('exit_mode', 'N/A')
            ret = row.get('Ann. Return %', 0)
            sharpe = row.get('Sharpe', 0)
            win_rate = row.get('Win Rate', 0)
            mdd = abs(float(row.get('Max DD %', row.get('Max Drawdown %', 0))))
            avg_holding = row.get('Avg Holding Days', 0)
            max_wins = row.get('Max Win Streak', 0)
            max_losses = row.get('Max Loss Streak', 0)

            strategies.append({
                'name': f"{pattern.upper()} {exit_mode}",
                'return': ret,
                'sharpe': sharpe,
                'win_rate': win_rate,
                'mdd': mdd,
                'avg_holding': avg_holding,
                'max_wins': max_wins,
                'max_losses': max_losses
            })

        return strategies
    except Exception as e:
        logger.warning(f"âš ï¸ ç„¡æ³•ç²å– Top ç­–ç•¥: {e}")
        return []


def generate_recommendation_report(signals_df, backtest_df):
    """
    ç”Ÿæˆæ—¥å¸¸æ¨è–¦å ±å‘Š (Markdown æ ¼å¼)

    åŒ…å«:
    - æœ¬æ—¥è¨Šè™Ÿçµ±è¨ˆ (ç•¶å¤©æª¢æ¸¬åˆ°çš„è¨Šè™Ÿ)
    - æœ¬æ—¥æ¨è–¦æ¸…å–® (ç•¶å¤©çš„æ¨è–¦è¨Šè™Ÿè©³ç´°åˆ—è¡¨)
    - éå»ä¸€é€±æ¨è–¦æ¸…å–® (è¿‘ 7 å¤©çš„æ¨è–¦è¨Šè™Ÿæ¸…å–®)
    - Top 3 ç­–ç•¥çµ±è¨ˆ
    """
    logger.info("ç”Ÿæˆæ¨è–¦å ±å‘Š...")

    # å³ä½¿ç„¡è¨Šè™Ÿä¹Ÿç”Ÿæˆå ±å‘Š
    try:
        output_dir = RESULTS_DIR
        os.makedirs(output_dir, exist_ok=True)

        today_str = date.today().strftime('%Y-%m-%d')

        # ç”Ÿæˆ Markdown å ±å‘Š
        report = f"""# CatBoost Enhanced è‚¡ç¥¨è¨Šè™Ÿå ±å‘Š
**æƒææ—¥æœŸ**: {today_str}
**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“Š æœ¬æ—¥è¨Šè™Ÿçµ±è¨ˆ

"""

        if signals_df is None or signals_df.empty:
            report += "- **ç¸½è¨Šè™Ÿæ•¸**: 0\n\n"
            report += "**æœ¬æ—¥ç„¡ç¬¦åˆæ¢ä»¶çš„å‹æ…‹è¨Šè™Ÿã€‚**\n\n"
        else:
            report += f"- **ç¸½è¨Šè™Ÿæ•¸**: {len(signals_df)}\n\n"
        
        report += "\n---\n\n"

        # æœ¬æ—¥æ¨è–¦æ¸…å–® (åªåœ¨æœ‰è¨Šè™Ÿæ™‚é¡¯ç¤º)
        if signals_df is not None and not signals_df.empty:
            # ç¯©é¸æ¨è–¦çš„è¨Šè™Ÿ (A/B ç´š)
            recommended = signals_df[signals_df['pred_label'] >= 2].copy()
            
            report += "## ğŸ“‹ æœ¬æ—¥æ¨è–¦æ¸…å–® (A/B ç´šã€æœªçªç ´)\n\n"

            # ç¯©é¸: æ¨è–¦ç­‰ç´š (A/B) + ç‹€æ…‹ç‚º"ç­‰å¾…çªç ´"
            recommended_not_broken = recommended[recommended['status'] == 'ç­‰å¾…çªç ´'].copy()

            if len(recommended_not_broken) == 0:
                report += "æœ¬æ—¥ç„¡ç¬¦åˆæ¢ä»¶çš„æ¨è–¦è¨Šè™Ÿ (æœªçªç ´)ã€‚\n"
            else:
                # æŒ‰è·é›¢% æ’åº (å„ªå…ˆé¡¯ç¤ºé›¢è²·å…¥åƒ¹è¿‘çš„)
                recommended_sorted = recommended_not_broken.sort_values('distance_pct')

                # æŒ‰ç­‰ç´šé¡¯ç¤º
                for grade in ['A', 'B']:
                    grade_signals = recommended_sorted[recommended_sorted['pred_grade'] == grade].copy()
                    if len(grade_signals) == 0:
                        continue

                    report += f"### {grade} ç´šæ¨è–¦ ({len(grade_signals)} å€‹)\n\n"

                    # è¡¨æ ¼é ­
                    report += "| ä»£ç¢¼ | Pattern | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | è·é›¢% | ç‹€æ…‹ | å¹´åŒ–å ±é…¬ | å‹ç‡ | Sharpe | MDD | é€£å‹ | é€£æ•— |\n"
                    report += "|------|---------|--------|--------|--------|-------|------|---------|------|--------|-----|-------|-------|\n"

                    for _, row in grade_signals.head(50).iterrows():  # é™åˆ¶æ¯ç´šæœ€å¤š 50 å€‹
                        sid = str(row['sid']) if 'sid' in row and pd.notna(row['sid']) else 'N/A'
                        pattern = str(row.get('pattern_type', 'N/A')).upper()
                        current = float(row.get('current_price', 0))
                        buy = float(row.get('buy_price', 0))
                        stop = float(row.get('stop_price', 0))
                        dist = float(row.get('distance_pct', 0))
                        status = str(row.get('status', 'N/A'))

                        line = f"| {sid} | {pattern} | {current:.2f} | {buy:.2f} | {stop:.2f} | {dist:.1f}% | {status}"

                        # å¹´åŒ–å ±é…¬
                        if 'Ann. Return %' in row and pd.notna(row['Ann. Return %']):
                            ret = float(row['Ann. Return %'])
                            line += f" | {ret:.1f}%"
                        else:
                            line += " | N/A"

                        # å‹ç‡
                        if 'Win Rate' in row and pd.notna(row['Win Rate']):
                            win = float(row['Win Rate'])
                            line += f" | {win:.1f}%"
                        else:
                            line += " | N/A"

                        # Sharpe
                        if 'Sharpe' in row and pd.notna(row['Sharpe']):
                            sharpe = float(row['Sharpe'])
                            line += f" | {sharpe:.2f}"
                        else:
                            line += " | N/A"

                        # Max Drawdown
                        if 'Max Drawdown %' in row and pd.notna(row['Max Drawdown %']):
                            mdd = float(row['Max Drawdown %'])
                            line += f" | {mdd:.1f}%"
                        else:
                            line += " | N/A"

                        # é€£å‹æ¬¡æ•¸
                        if 'Max Win Streak' in row and pd.notna(row['Max Win Streak']):
                            wins = int(row['Max Win Streak'])
                            line += f" | {wins}"
                        else:
                            line += " | N/A"

                        # é€£æ•—æ¬¡æ•¸
                        if 'Max Loss Streak' in row and pd.notna(row['Max Loss Streak']):
                            losses = int(row['Max Loss Streak'])
                            line += f" | {losses}"
                        else:
                            line += " | N/A"

                        line += " |"
                        report += line + "\n"

                    report += "\n"

        report += "---\n\n"

        # éå»ä¸€é€±æ¨è–¦æ¸…å–® (é‚„æ²’çªç ´çš„è¨Šè™Ÿ)
        report += "## ğŸ“… éå»ä¸€é€±æ¨è–¦æ¸…å–® (æœªçªç ´)\n\n"

        # è¼‰å…¥éå»ä¸€é€±çš„è¨Šè™Ÿï¼Œä½†éœ€è¦æª¢æŸ¥ç›®å‰çš„ç‹€æ…‹
        # åªé¡¯ç¤ºåœ¨éå» 7 å¤©å‡ºç¾ä¸”åˆ°ç¾åœ¨é‚„æ²’çªç ´çš„è¨Šè™Ÿ
        try:
            weekly_signals = load_weekly_signals()
            if weekly_signals.empty or len(weekly_signals) == 0:
                report += "éå»ä¸€é€±ç„¡æ¨è–¦è¨Šè™Ÿç´€éŒ„ã€‚\n"
            else:
                # ç¯©é¸ A/B ç´š
                weekly_recommended = weekly_signals[weekly_signals['pred_label'] >= 2].copy()

                if len(weekly_recommended) == 0:
                    report += "éå»ä¸€é€±ç„¡ A/B ç´šæ¨è–¦è¨Šè™Ÿã€‚\n"
                else:
                    # é‡æ–°è¼‰å…¥æœ€æ–°çš„å¸‚å ´æ•¸æ“šï¼Œæª¢æŸ¥é€™äº›è¨Šè™Ÿç¾åœ¨æ˜¯å¦é‚„æ²’çªç ´
                    # ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘å‡è¨­è¨Šè™Ÿè³‡æ–™ä¸­å·²ç¶“æœ‰æœ€æ–°çš„ç‹€æ…‹
                    weekly_not_broken = weekly_recommended[weekly_recommended.get('status', '') == 'ç­‰å¾…çªç ´'].copy()

                    if len(weekly_not_broken) == 0:
                        report += "éå»ä¸€é€±çš„æ¨è–¦è¨Šè™Ÿéƒ½å·²çªç ´æˆ–éæœŸã€‚\n"
                    else:
                        # æŒ‰æ—¥æœŸåˆ†çµ„é¡¯ç¤ºæ¨è–¦æ¸…å–®
                        for scan_date in sorted(weekly_not_broken['scan_date'].unique()):
                            day_signals = weekly_not_broken[weekly_not_broken['scan_date'] == scan_date]
                            report += f"### {scan_date} ({len(day_signals)} å€‹)\n\n"

                            # è¡¨æ ¼é ­
                            report += "| ä»£ç¢¼ | Pattern | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | è·é›¢% | ç´šåˆ¥ | å¹´åŒ–å ±é…¬ | Sharpe |\n"
                            report += "|------|---------|--------|--------|--------|-------|------|---------|--------|\n"

                            for _, row in day_signals.iterrows():
                                sid = str(row.get('sid', 'N/A'))
                                pattern = str(row.get('pattern_type', 'N/A')).upper()
                                current = float(row.get('current_price', 0)) if 'current_price' in row else 0
                                buy = float(row.get('buy_price', 0)) if 'buy_price' in row else 0
                                stop = float(row.get('stop_price', 0)) if 'stop_price' in row else 0
                                dist = float(row.get('distance_pct', 0)) if 'distance_pct' in row else 0
                                grade = str(row.get('pred_grade', 'N/A'))

                                line = f"| {sid} | {pattern} | {current:.2f} | {buy:.2f} | {stop:.2f} | {dist:.1f}% | {grade}"

                                # å¹´åŒ–å ±é…¬
                                if 'Ann. Return %' in row and pd.notna(row['Ann. Return %']):
                                    ret = float(row['Ann. Return %'])
                                    line += f" | {ret:.1f}%"
                                else:
                                    line += " | N/A"

                                # Sharpe
                                if 'Sharpe' in row and pd.notna(row['Sharpe']):
                                    sharpe = float(row['Sharpe'])
                                    line += f" | {sharpe:.2f}"
                                else:
                                    line += " | N/A"

                                line += " |\n"
                                report += line

                            report += "\n"
        except Exception as e:
            logger.warning(f"âš ï¸ éå»ä¸€é€±è¨Šè™Ÿè¼‰å…¥å¤±æ•—: {e}")
            report += f"ç„¡æ³•è¼‰å…¥éå»ä¸€é€±è¨Šè™Ÿ: {e}\n"

        report += "---\n\n"

        # Top 3 ç­–ç•¥
        report += "## ğŸ† Top 3 Strategies (CatBoost Enhanced)\n\n"

        report += "> **èªªæ˜**ï¼šä»¥ä¸‹ç¸¾æ•ˆç‚º CatBoost æ¨¡å‹éæ¿¾å¾Œçš„å›æ¸¬çµæœ\n"
        report += "> - åªä½¿ç”¨ **A/B ç´šè¨Šè™Ÿ**ï¼ˆæ¨¡å‹é æ¸¬ä¿¡å¿ƒåº¦é«˜çš„è¨Šè™Ÿï¼‰\n"
        report += "> - ç­–ç•¥åç¨± = Pattern (HTF/CUP/VCP) + Exit Mode (fixed_r2_t20 ç­‰)\n"
        report += "> - ç¸¾æ•ˆæŒ‡æ¨™ä»£è¡¨è©²ç­–ç•¥çµ„åˆçš„æ­·å²å¹³å‡è¡¨ç¾\n\n"

        strategies_by_return = get_top_strategies(backtest_df, n=3)
        if strategies_by_return:
            # ä¾å¹´åŒ–å ±é…¬æ’åº
            report += "### ä¾å¹´åŒ–å ±é…¬æ’åº\n\n"
            for i, strat in enumerate(strategies_by_return, 1):
                report += f"""{i}. **{strat['name']}**
   - å¹´åŒ–å ±é…¬: **{strat['return']:.1f}%**, Sharpe: **{strat['sharpe']:.2f}**, å‹ç‡: {strat['win_rate']:.1f}%
   - å¹³å‡æŒå€‰: {strat['avg_holding']:.1f} å¤©, MDD: -{strat['mdd']:.1f}%
   - é€£å‹/é€£æ•—: {int(strat['max_wins'])} / {int(strat['max_losses'])}

"""

            # ä¾ Sharpe æ’åº
            report += "### ä¾ Sharpe æ’åº\n\n"
            strategies_by_sharpe = sorted(strategies_by_return, key=lambda x: x['sharpe'], reverse=True)
            for i, strat in enumerate(strategies_by_sharpe, 1):
                report += f"""{i}. **{strat['name']}**
   - Sharpe: **{strat['sharpe']:.2f}**, å¹´åŒ–å ±é…¬: **{strat['return']:.1f}%**, å‹ç‡: {strat['win_rate']:.1f}%
   - å¹³å‡æŒå€‰: {strat['avg_holding']:.1f} å¤©, MDD: -{strat['mdd']:.1f}%
   - é€£å‹/é€£æ•—: {int(strat['max_wins'])} / {int(strat['max_losses'])}

"""
        else:
            report += "ç„¡ backtest æ•¸æ“šå¯ç”¨ã€‚\n"

        # ä¿å­˜å ±å‘Š
        report_file = output_dir / f'catboost_daily_summary_{today_str}.md'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)

        logger.info(f"âœ“ å ±å‘Šå·²ä¿å­˜: {report_file}")

        # åŒæ™‚ä¿å­˜æ¨è–¦è¨Šè™Ÿçš„ CSV (ç”¨æ–¼å¾ŒçºŒè¼‰å…¥ä¸€é€±æ¸…å–®)
        csv_file = output_dir / f'daily_scan_{today_str}.csv'
        if signals_df is not None and not signals_df.empty:
            # ç¯©é¸æ¨è–¦è¨Šè™Ÿ (A/B ç´š)
            recommended = signals_df[signals_df['pred_label'] >= 2]
            if len(recommended) > 0:
                cols = ['sid', 'pattern_type', 'exit_mode', 'pred_grade', 'pred_proba_A', 'pred_proba_B']
                if 'Ann. Return %' in recommended.columns:
                    cols.append('Ann. Return %')
                if 'Win Rate' in recommended.columns:
                    cols.append('Win Rate')
                available_cols = [c for c in cols if c in recommended.columns]
                recommended[available_cols].to_csv(csv_file, index=False, encoding='utf-8-sig')
            else:
                # ç©ºæ¨è–¦ä¹Ÿè¦ä¿å­˜
                pd.DataFrame().to_csv(csv_file, index=False, encoding='utf-8-sig')
        else:
            # ç©ºæ¨è–¦ä¹Ÿè¦ä¿å­˜ï¼ˆç”¨æ–¼è¼‰å…¥ä¸€é€±æ¸…å–®æ™‚çš„è¨ˆæ•¸ï¼‰
            pd.DataFrame().to_csv(csv_file, index=False, encoding='utf-8-sig')

        logger.info(f"âœ“ è¨Šè™Ÿæ¸…å–®å·²ä¿å­˜: {csv_file}")

        # è¼¸å‡ºæ‘˜è¦åˆ° terminal
        logger.info("\n" + "="*80)
        logger.info("ã€ä»Šæ—¥æƒæå®Œæˆã€‘")
        logger.info("="*80)
        if signals_df is not None and not signals_df.empty:
            recommended_count = len(signals_df[signals_df['pred_label'] >= 2])
            logger.info(f"ç¸½è¨Šè™Ÿæ•¸: {len(signals_df)}")
            logger.info(f"æ¨è–¦è¨Šè™Ÿ: {recommended_count}")
        else:
            logger.info("ç¸½è¨Šè™Ÿæ•¸: 0")
        logger.info(f"å ±å‘Š: {report_file}")
        logger.info("="*80)

    except Exception as e:
        logger.error(f"âŒ å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
        import traceback
        logger.error(traceback.format_exc())


def generate_html_report(output_df, full_df):
    """ç”Ÿæˆ HTML å ±å‘Š"""
    html = """
    <html>
    <head>
        <meta charset="utf-8">
        <title>Daily ML Scanner Report</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; }
            h1 { color: #333; }
            table { border-collapse: collapse; width: 100%; margin: 20px 0; }
            th { background-color: #4CAF50; color: white; padding: 10px; text-align: left; }
            td { padding: 10px; border-bottom: 1px solid #ddd; }
            tr:hover { background-color: #f5f5f5; }
            .grade-A { background-color: #90EE90; font-weight: bold; }
            .grade-B { background-color: #FFD700; font-weight: bold; }
            .grade-C { background-color: #FFA500; }
            .grade-D { background-color: #FF6347; }
            .summary { background-color: #f9f9f9; padding: 15px; margin: 20px 0; }
        </style>
    </head>
    <body>
        <h1>Daily ML Scanner Report</h1>
        <p>Generated: """ + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + """</p>

        <div class="summary">
            <h2>Summary</h2>
            <p>Total Signals: """ + str(len(full_df)) + """</p>
            <p>Recommended (A/B): """ + str(len(output_df)) + """</p>
        </div>

        <h2>Recommended Signals</h2>
        <table>
            <tr>
    """

    # è¡¨é ­
    for col in output_df.columns:
        html += f"<th>{col}</th>"
    html += "</tr>\n"

    # è¡¨æ ¼è¡Œ
    for _, row in output_df.iterrows():
        grade = row.get('pred_grade', 'N/A')
        grade_class = f"grade-{grade}"
        html += f"<tr><td class='{grade_class}'>" + "</td><td>".join(
            str(v) for v in row.values
        ) + "</td></tr>\n"

    html += """
        </table>
    </body>
    </html>
    """

    return html


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--output-dir', default=str(RESULTS_DIR), help='è¼¸å‡ºç›®éŒ„')
    args = parser.parse_args()

    logger.info("="*80)
    logger.info("Daily ML Scanner")
    logger.info("="*80)

    # 0. æ›´æ–°æ¯æ—¥æ•¸æ“š
    logger.info("\n>>> æ›´æ–°æ¯æ—¥æ•¸æ“š...")
    try:
        from scripts.update_daily_data import main as update_data
        update_data()
    except Exception as e:
        logger.error(f"âš ï¸ æ•¸æ“šæ›´æ–°å¤±æ•—: {e}")

    # 1. è¼‰å…¥æ¨¡å‹å’Œ backtest çµæœ
    model, feature_info = load_model_and_features()
    if model is None:
        logger.error("âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹ï¼Œä¸­æ­¢åŸ·è¡Œ")
        return

    feature_importance = load_feature_importance()
    backtest_df = load_backtest_performance()

    # 2. è¼‰å…¥ä»Šæ—¥è¨Šè™Ÿ
    signals_df = get_today_signals()
    
    # å¦‚æœæœ‰è¨Šè™Ÿï¼Œé€²è¡Œé æ¸¬å’Œç‰¹å¾µè™•ç†
    if signals_df is not None and not signals_df.empty:
        # 3. æº–å‚™ç‰¹å¾µ
        signals_df = prepare_features_for_model(signals_df)
        if signals_df is None:
            logger.error("âŒ ç‰¹å¾µæº–å‚™å¤±æ•—")
            signals_df = pd.DataFrame()  # è¨­ç‚ºç©ºï¼Œç¹¼çºŒç”Ÿæˆå ±å‘Š

        # 4. é æ¸¬å“è³ª
        if signals_df is not None and not signals_df.empty:
            signals_df = predict_signal_quality(model, feature_info, signals_df)
            if signals_df is None:
                logger.error("âŒ é æ¸¬å¤±æ•—")
                signals_df = pd.DataFrame()

        # 5. æ·»åŠ  backtest æ€§èƒ½
        if signals_df is not None and not signals_df.empty and backtest_df is not None:
            signals_df = enrich_with_backtest_performance(signals_df, backtest_df)
    else:
        logger.info("ä»Šæ—¥ç„¡è¨Šè™Ÿï¼Œåƒ…ç”Ÿæˆ Top Strategies å ±å‘Š")
        signals_df = pd.DataFrame()  # ç©ºçš„ DataFrame

    # 6. ç”Ÿæˆå ±å‘Š (å³ä½¿ç„¡è¨Šè™Ÿä¹Ÿç”Ÿæˆï¼ŒåŒ…å« Top ç­–ç•¥çµ±è¨ˆ)
    generate_recommendation_report(signals_df, backtest_df)

    logger.info("\n" + "="*80)
    logger.info("âœ… Daily Scanner å®Œæˆ")
    logger.info("="*80)


if __name__ == "__main__":
    main()
