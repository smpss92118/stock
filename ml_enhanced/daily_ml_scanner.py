#!/usr/bin/env python3
"""
Daily ML-Enhanced Stock Scanner

æ¯æ—¥æƒæç³»çµ±ï¼ŒåŒæ™‚è¼¸å‡º:
1. åŸå§‹ç­–ç•¥è¨Šè™Ÿ (HTF Trailing, CUP R=2.0)
2. ML å¢å¼·è¨Šè™Ÿ (ç¶“é ML 0.4 threshold éæ¿¾)
3. é€²å‡ºå ´é»ã€é¢¨éšªã€ML è©•åˆ†

Usage:
    python stock/ml_enhanced/daily_ml_scanner.py
    
Output:
    stock/ml_enhanced/daily_reports/YYYY-MM-DD/ml_daily_summary.md
    
Crontab:
    0 19 * * * cd /Users/sony/ml_stock && python stock/ml_enhanced/daily_ml_scanner.py
"""

import sys
import os
from datetime import datetime
import pandas as pd
import pickle

# Add paths
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from scripts.update_daily_data import main as update_data
from scripts.run_daily_scan import scan_latest_date, load_data
from src.strategies.htf import detect_htf
from src.strategies.cup import detect_cup
from src.strategies.vcp import detect_vcp

# Import shared modules
from src.utils.logger import setup_logger
from src.ml.features import extract_ml_features

# Configuration
MODEL_PATH = os.path.join(os.path.dirname(__file__), 'models/stock_selector.pkl')
FEATURE_INFO_PATH = os.path.join(os.path.dirname(__file__), 'models/feature_info.pkl')
OUTPUT_BASE = os.path.join(os.path.dirname(__file__), 'daily_reports')
BACKTEST_RESULTS_PATH = os.path.join(os.path.dirname(__file__), 'results/ml_backtest_final.csv')

# Setup Logger
logger = setup_logger('daily_ml_scanner')

def load_ml_model():
    """è¼‰å…¥ ML æ¨¡å‹"""
    try:
        with open(MODEL_PATH, 'rb') as f:
            model = pickle.load(f)
        with open(FEATURE_INFO_PATH, 'rb') as f:
            feature_info = pickle.load(f)
        return model, feature_info['feature_cols']
    except Exception as e:
        logger.error(f"âš ï¸ ML æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None, None

def load_backtest_results():
    """è¼‰å…¥å›æ¸¬çµæœ"""
    try:
        if not os.path.exists(BACKTEST_RESULTS_PATH):
            return None
        
        df = pd.read_csv(BACKTEST_RESULTS_PATH)
        return df
    except Exception as e:
        logger.error(f"âš ï¸ å›æ¸¬çµæœè¼‰å…¥å¤±æ•—: {e}")
        return None

def predict_signal_quality(model, feature_cols, features_dict):
    """é æ¸¬è¨Šè™Ÿå“è³ª"""
    if model is None:
        return 0.5  # Default
    
    try:
        X = pd.DataFrame([features_dict])[feature_cols]
        proba = model.predict_proba(X)[0][1]
        return proba
    except Exception as e:
        logger.warning(f"    âš ï¸ ML é æ¸¬å¤±æ•—: {e}")
        return 0.5

def scan_with_ml(df, model, feature_cols):
    """æƒæä¸¦æ·»åŠ  ML è©•åˆ†"""
    latest_date = df['date'].max()
    logger.info(f"\næƒææ—¥æœŸ: {latest_date}")
    
    latest_stocks = df[df['date'] == latest_date]['sid'].unique()
    logger.info(f"è‚¡ç¥¨æ•¸é‡: {len(latest_stocks)}")
    
    signals = []
    processed = 0
    
    for sid in latest_stocks:
        processed += 1
        if processed % 100 == 0:
            logger.info(f"å·²è™•ç† {processed}/{len(latest_stocks)} æª”è‚¡ç¥¨...")
        
        stock_df = df[df['sid'] == sid].reset_index(drop=True)
        n_rows = len(stock_df)
        
        if n_rows < 126:
            continue
        
        i = n_rows - 1
        window = stock_df.iloc[i - 126 + 1 : i + 1]
        row_today = stock_df.iloc[i]
        
        if row_today['date'] != latest_date:
            continue
        
        # MA info
        ma_info = {
            'ma50': row_today.get('ma50', 0),
            'ma150': row_today.get('ma150', 0),
            'ma200': row_today.get('ma200', 0),
            'low52': row_today.get('low52', 0)
        }
        
        rs_rating = row_today.get('rs_rating', 0)
        
        # Detect HTF
        is_htf, htf_buy, htf_stop, htf_grade = detect_htf(window, rs_rating=rs_rating)
        if is_htf and htf_buy and htf_stop and row_today['close'] > htf_stop:
            # Add temporary pattern info to row for feature extraction
            row_today_htf = row_today.copy()
            row_today_htf['htf_buy_price'] = htf_buy
            row_today_htf['htf_stop_price'] = htf_stop
            row_today_htf['htf_grade'] = htf_grade
            
            features = extract_ml_features(row_today_htf, 'htf')
            ml_proba = predict_signal_quality(model, feature_cols, features)
            
            signals.append({
                'date': latest_date,
                'sid': sid,
                'name': row_today['name'],
                'pattern': 'HTF',
                'buy_price': round(htf_buy, 2),
                'stop_price': round(htf_stop, 2),
                'risk_pct': round((htf_buy - htf_stop) / htf_buy * 100, 2),
                'grade': htf_grade if htf_grade else 'C',
                'current_price': round(row_today['close'], 2),
                'distance_pct': round((htf_buy - row_today['close']) / htf_buy * 100, 2),
                'ml_proba': round(ml_proba, 3),
                'ml_selected': ml_proba >= 0.4,
                'rs_rating': round(rs_rating, 1)
            })
        
        # Detect CUP
        is_cup, cup_buy, cup_stop = detect_cup(window, ma_info, rs_rating=rs_rating)
        if is_cup and cup_buy and cup_stop and row_today['close'] > cup_stop:
            # Add temporary pattern info to row for feature extraction
            row_today_cup = row_today.copy()
            row_today_cup['cup_buy_price'] = cup_buy
            row_today_cup['cup_stop_price'] = cup_stop
            
            features = extract_ml_features(row_today_cup, 'cup')
            ml_proba = predict_signal_quality(model, feature_cols, features)
            
            signals.append({
                'date': latest_date,
                'sid': sid,
                'name': row_today['name'],
                'pattern': 'CUP',
                'buy_price': round(cup_buy, 2),
                'stop_price': round(cup_stop, 2),
                'risk_pct': round((cup_buy - cup_stop) / cup_buy * 100, 2),
                'grade': 'N/A',
                'current_price': round(row_today['close'], 2),
                'distance_pct': round((cup_buy - row_today['close']) / cup_buy * 100, 2),
                'ml_proba': round(ml_proba, 3),
                'ml_selected': ml_proba >= 0.4,
                'rs_rating': round(rs_rating, 1)
            })
    
    return signals, latest_date

def generate_ml_report(signals, scan_date, df_full=None):
    """ç”Ÿæˆ ML å¢å¼·å ±å‘Šï¼ˆå³ä½¿ä»Šæ—¥ç„¡è¨Šè™Ÿä¹Ÿç”Ÿæˆï¼‰"""
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    today_str = datetime.now().strftime('%Y-%m-%d')
    output_dir = os.path.join(OUTPUT_BASE, today_str)
    os.makedirs(output_dir, exist_ok=True)
    
    # è™•ç†è¨Šè™Ÿæ•¸æ“š
    if signals:
        df_signals = pd.DataFrame(signals)
        # åˆ†é›¢ ML é¸ä¸­å’Œæœªé¸ä¸­
        ml_selected = df_signals[df_signals['ml_selected'] == True]
        ml_rejected = df_signals[df_signals['ml_selected'] == False]
    else:
        df_signals = pd.DataFrame()
        ml_selected = pd.DataFrame()
        ml_rejected = pd.DataFrame()
    
    # ç”Ÿæˆå ±å‘Š
    report_path = os.path.join(output_dir, 'ml_daily_summary.md')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"# ML-Enhanced è‚¡ç¥¨è¨Šè™Ÿå ±å‘Š\n")
        f.write(f"**æƒææ—¥æœŸ**: {scan_date}\n")
        f.write(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        # çµ±è¨ˆæ‘˜è¦
        f.write(f"## ğŸ“Š æœ¬æ—¥è¨Šè™Ÿçµ±è¨ˆ\n\n")
        
        if not df_signals.empty:
            f.write(f"- **ç¸½è¨Šè™Ÿæ•¸**: {len(df_signals)}\n")
            f.write(f"- **ML æ¨è–¦**: {len(ml_selected)} (é«˜å“è³ª)\n")
            f.write(f"- **åŸå§‹è¨Šè™Ÿ**: {len(ml_rejected)} (åƒè€ƒ)\n\n")
        else:
            f.write(f"- **ç¸½è¨Šè™Ÿæ•¸**: 0\n\n")
            f.write("**æœ¬æ—¥ç„¡ç¬¦åˆæ¢ä»¶çš„å‹æ…‹è¨Šè™Ÿã€‚**\n\n")
        
        f.write("---\n\n")
        
        # ML æ¨è–¦è¨Šè™Ÿ
        if not ml_selected.empty:
            f.write(f"## âœ… ML æ¨è–¦è¨Šè™Ÿ ({len(ml_selected)} æª”)\n\n")
            f.write("> **ML æ©Ÿç‡ â‰¥ 0.4**ï¼šé«˜å“è³ªè¨Šè™Ÿï¼Œå»ºè­°å„ªå…ˆç ”ç©¶\n\n")
            
            # HTF æ¨è–¦
            htf_ml = ml_selected[ml_selected['pattern'] == 'HTF'].sort_values('ml_proba', ascending=False)
            if not htf_ml.empty:
                f.write(f"### ğŸš€ HTF å‹æ…‹ ({len(htf_ml)} æª”)\n\n")
                f.write("**æ¨è–¦ç­–ç•¥**: Trailing Stop (1.5R trigger, MA20)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | è‚¡ç¥¨åç¨± | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | è·é›¢% | Grade | MLåˆ†æ•¸ | RS Rating |\n")
                f.write("|---------|---------|--------|--------|--------|-------|-------|--------|----------|\n")
                for _, row in htf_ml.iterrows():
                    f.write(f"| **{row['sid']}** | {row['name']} | {row['current_price']} | ")
                    f.write(f"{row['buy_price']} | {row['stop_price']} | {row['distance_pct']}% | ")
                    f.write(f"{row['grade']} | **{row['ml_proba']}** | {row['rs_rating']} |\n")
                f.write("\n")
            
            # CUP æ¨è–¦
            cup_ml = ml_selected[ml_selected['pattern'] == 'CUP'].sort_values('ml_proba', ascending=False)
            if not cup_ml.empty:
                f.write(f"### ğŸ† CUP å‹æ…‹ ({len(cup_ml)} æª”)\n\n")
                f.write("**æ¨è–¦ç­–ç•¥**: Fixed Exit (R=2.0, T=20 æˆ– R=3.0, T=20)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | è‚¡ç¥¨åç¨± | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | è·é›¢% | MLåˆ†æ•¸ | RS Rating |\n")
                f.write("|---------|---------|--------|--------|--------|-------|--------|----------|\n")
                for _, row in cup_ml.iterrows():
                    f.write(f"| **{row['sid']}** | {row['name']} | {row['current_price']} | ")
                    f.write(f"{row['buy_price']} | {row['stop_price']} | {row['distance_pct']}% | ")
                    f.write(f"**{row['ml_proba']}** | {row['rs_rating']} |\n")
                f.write("\n")
            
            f.write("---\n\n")
        
        # åŸå§‹è¨Šè™Ÿï¼ˆæœªè¢« ML é¸ä¸­ï¼‰
        if not ml_rejected.empty:
            f.write(f"## ğŸ“‹ å…¶ä»–åŸå§‹è¨Šè™Ÿ ({len(ml_rejected)} æª”)\n\n")
            f.write("> **ML æ©Ÿç‡ < 0.4**ï¼šå“è³ªè¼ƒä½ï¼Œåƒ…ä¾›åƒè€ƒ\n\n")
            
            # HTF å…¶ä»–
            htf_other = ml_rejected[ml_rejected['pattern'] == 'HTF'].sort_values('ml_proba', ascending=False)
            if not htf_other.empty:
                f.write(f"### HTF å‹æ…‹ ({len(htf_other)} æª”)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | Grade | MLåˆ†æ•¸ |\n")
                f.write("|---------|--------|--------|--------|-------|--------|\n")
                for _, row in htf_other.iterrows():
                    f.write(f"| {row['sid']} | {row['current_price']} | {row['buy_price']} | ")
                    f.write(f"{row['stop_price']} | {row['grade']} | {row['ml_proba']} |\n")
                f.write("\n")
            
            # CUP å…¶ä»–
            cup_other = ml_rejected[ml_rejected['pattern'] == 'CUP'].sort_values('ml_proba', ascending=False)
            if not cup_other.empty:
                f.write(f"### CUP å‹æ…‹ ({len(cup_other)} æª”)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | MLåˆ†æ•¸ |\n")
                f.write("|---------|--------|--------|--------|--------|\n")
                for _, row in cup_other.iterrows():
                    f.write(f"| {row['sid']} | {row['current_price']} | {row['buy_price']} | ")
                    f.write(f"{row['stop_price']} | {row['ml_proba']} |\n")
                f.write("\n")
        
        f.write("---\n\n")
        
        # éå»ä¸€é€±è¨Šè™Ÿå½™æ•´
        if df_full is not None:
            f.write("## ğŸ“… éå»ä¸€é€±è¨Šè™Ÿå½™æ•´\n\n")
            try:
                from datetime import timedelta
                today = pd.to_datetime(scan_date)
                start_date = today - timedelta(days=7)
                
                df_week = df_full[pd.to_datetime(df_full['date']) >= start_date].copy()
                
                if not df_week.empty:
                    weekly_signals = []
                    
                    # HTF signals - check if column exists
                    if 'is_htf' in df_week.columns:
                        htf_df = df_week[df_week['is_htf'] == True].copy()
                        for _, row in htf_df.iterrows():
                            if pd.notna(row.get('htf_buy_price')) and pd.notna(row.get('htf_stop_price')):
                                weekly_signals.append({
                                    'date': pd.to_datetime(row['date']).strftime('%Y-%m-%d'),
                                    'sid': row['sid'],
                                    'name': row.get('name', ''),
                                    'pattern': 'HTF',
                                    'buy_price': round(row['htf_buy_price'], 2),
                                    'stop_price': round(row['htf_stop_price'], 2),
                                    'grade': row.get('htf_grade', 'N/A')
                                })
                    
                    # CUP signals - check if column exists
                    if 'is_cup' in df_week.columns:
                        cup_df = df_week[df_week['is_cup'] == True].copy()
                        for _, row in cup_df.iterrows():
                            if pd.notna(row.get('cup_buy_price')) and pd.notna(row.get('cup_stop_price')):
                                weekly_signals.append({
                                    'date': pd.to_datetime(row['date']).strftime('%Y-%m-%d'),
                                    'sid': row['sid'],
                                    'name': row.get('name', ''),
                                    'pattern': 'CUP',
                                    'buy_price': round(row['cup_buy_price'], 2),
                                    'stop_price': round(row['cup_stop_price'], 2),
                                    'grade': 'N/A'
                                })
                    
                    if weekly_signals:
                        df_weekly = pd.DataFrame(weekly_signals)
                        
                        # HTF weekly
                        htf_weekly = df_weekly[df_weekly['pattern'] == 'HTF']
                        if not htf_weekly.empty:
                            f.write(f"### ğŸš€ HTF å‹æ…‹è¨Šè™Ÿ ({len(htf_weekly)} æª”)\n\n")
                            f.write("| æ—¥æœŸ | è‚¡ç¥¨ä»£è™Ÿ | è²·å…¥åƒ¹ | åœæåƒ¹ | Grade |\n")
                            f.write("|------|---------|--------|--------|-------|\n")
                            for _, row in htf_weekly.iterrows():
                                f.write(f"| {row['date']} | {row['sid']} | {row['buy_price']} | {row['stop_price']} | {row['grade']} |\n")
                            f.write("\n")
                        
                        # CUP weekly
                        cup_weekly = df_weekly[df_weekly['pattern'] == 'CUP']
                        if not cup_weekly.empty:
                            f.write(f"### ğŸ† CUP å‹æ…‹è¨Šè™Ÿ ({len(cup_weekly)} æª”)\n\n")
                            f.write("| æ—¥æœŸ | è‚¡ç¥¨ä»£è™Ÿ | è²·å…¥åƒ¹ | åœæåƒ¹ |\n")
                            f.write("|------|---------|--------|--------|\n")
                            for _, row in cup_weekly.iterrows():
                                f.write(f"| {row['date']} | {row['sid']} | {row['buy_price']} | {row['stop_price']} |\n")
                            f.write("\n")
                        
                        f.write(f"**çµ±è¨ˆ**: å…± {len(df_weekly)} å€‹è¨Šè™Ÿä¾†è‡ªéå» 7 å¤©\n\n")
                    else:
                        f.write("éå»ä¸€é€±ç„¡ç¬¦åˆæ¢ä»¶çš„è¨Šè™Ÿã€‚\n\n")
                else:
                    f.write("éå»ä¸€é€±ç„¡æ•¸æ“šè¨˜éŒ„ã€‚\n\n")
            except Exception as e:
                logger.error(f"âš ï¸ è®€å–æ­·å²è¨Šè™ŸéŒ¯èª¤: {e}")
                f.write(f"âš ï¸ è®€å–æ­·å²è¨Šè™Ÿæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n\n")
            
            f.write("---\n\n")
        
        # Top Strategies (Dynamic)
        backtest_df = load_backtest_results()
        if backtest_df is not None and not backtest_df.empty:
            f.write("## ğŸ† Top 3 Strategies (ML-Enhanced)\n\n")
            
            # Sort by Annual Return
            top_strategies = backtest_df.sort_values('Ann. Return %', ascending=False).head(3)
            
            f.write("### ä¾å¹´åŒ–å ±é…¬æ’åº\n\n")
            for i, (_, row) in enumerate(top_strategies.iterrows(), 1):
                strategy_name = row['Strategy']
                ann_ret = row['Ann. Return %']
                sharpe = row['Sharpe']
                avg_hold = row.get('Avg Holding Days', 'N/A')
                max_win = row.get('Max Win Streak', 'N/A')
                max_loss = row.get('Max Loss Streak', 'N/A')
                mdd = row.get('Max DD %', 'N/A')
                
                f.write(f"{i}. **{strategy_name}**\n")
                f.write(f"   - å¹´åŒ–å ±é…¬: **{ann_ret}%**, Sharpe: **{sharpe}**\n")
                f.write(f"   - å¹³å‡æŒå€‰: {avg_hold} å¤©, MDD: {mdd}%\n")
                f.write(f"   - é€£å‹/é€£æ•—: {max_win} / {max_loss}\n\n")
            
            f.write("---\n\n")
        else:
            # Fallback if no backtest results
            f.write("## ğŸ† Top 3 Strategies (ML-Enhanced)\n\n")
            f.write("> âš ï¸ ç„¡æ³•è¼‰å…¥æœ€æ–°å›æ¸¬çµæœï¼Œè«‹æª¢æŸ¥ ml_backtest_final.csv\n\n")
            f.write("---\n\n")
        
        # äº¤æ˜“ç­–ç•¥èªªæ˜
        f.write("## ğŸ“– äº¤æ˜“ç­–ç•¥èªªæ˜\n\n")
        f.write("### HTF Trailing Stop\n")
        f.write("- **é€²å ´**: åƒ¹æ ¼çªç ´è²·å…¥åƒ¹\n")
        f.write("- **å‡ºå ´**: 1. é”åˆ° 1.5R å¾Œå•Ÿå‹• MA20 è¿½è¹¤æ­¢æ  2. è·Œç ´åœæåƒ¹\n")
        f.write("- **é æœŸ**: 153-171% å¹´åŒ–å ±é…¬\n\n")
        f.write("### CUP Fixed Exit (ML æ¨è–¦) â­\n")
        f.write("- **é€²å ´**: åƒ¹æ ¼çªç ´è²·å…¥åƒ¹\n")
        f.write("- **å‡ºå ´**: 2R ç›®æ¨™æˆ– 20 å¤©æ™‚é–“å‡ºå ´\n")
        f.write("- **é æœŸ**: 171% å¹´åŒ–å ±é…¬, Sharpe 2.99 (ML enhanced)\n\n")
        f.write("### ML åˆ†æ•¸è§£è®€\n")
        f.write("- **â‰¥ 0.4**: é«˜å“è³ªè¨Šè™Ÿï¼Œå‹ç‡ 70-78% â­\n")
        f.write("- **0.3-0.4**: ä¸­ç­‰å“è³ªï¼Œå‹ç‡ 60-70%\n")
        f.write("- **< 0.3**: ä½å“è³ªï¼Œå‹ç‡ < 60%\n\n")
    
    # å„²å­˜ CSV (å³ä½¿æ˜¯ç©ºçš„ä¹Ÿå„²å­˜)
    csv_path = os.path.join(output_dir, 'ml_signals.csv')
    if not df_signals.empty:
        df_signals.to_csv(csv_path, index=False)
    else:
        # å‰µå»ºç©º CSV
        pd.DataFrame(columns=['date', 'sid', 'name', 'pattern', 'buy_price', 'stop_price', 
                              'risk_pct', 'grade', 'current_price', 'distance_pct', 
                              'ml_proba', 'ml_selected', 'rs_rating']).to_csv(csv_path, index=False)
    
    logger.info(f"\nâœ… ML å ±å‘Šå·²å„²å­˜è‡³: {report_path}")
    logger.info(f"âœ… CSV å·²å„²å­˜è‡³: {csv_path}")
    
    # é¡¯ç¤ºæ‘˜è¦
    logger.info(f"\n{'='*60}")
    logger.info(f"ML æ¨è–¦è¨Šè™Ÿçµ±è¨ˆ")
    logger.info(f"{'='*60}")
    if not df_signals.empty:
        logger.info(f"HTF (ML â‰¥ 0.4): {len(ml_selected[ml_selected['pattern'] == 'HTF'])} æª”")
        logger.info(f"CUP (ML â‰¥ 0.4): {len(ml_selected[ml_selected['pattern'] == 'CUP'])} æª”")
        logger.info(f"ç¸½è¨ˆæ¨è–¦: {len(ml_selected)} æª”")
    else:
        logger.info(f"æœ¬æ—¥ç„¡è¨Šè™Ÿ")

def main():
    logger.info("="*60)
    logger.info("ML-Enhanced Daily Stock Scanner")
    logger.info("="*60)
    
    # 1. æ›´æ–°æ•¸æ“š
    logger.info("\n>>> æ›´æ–°æ¯æ—¥æ•¸æ“š...")
    try:
        update_data()
    except Exception as e:
        logger.error(f"âš ï¸ æ•¸æ“šæ›´æ–°å¤±æ•—: {e}")
    
    # 2. è¼‰å…¥ ML æ¨¡å‹
    logger.info("\n>>> è¼‰å…¥ ML æ¨¡å‹...")
    model, feature_cols = load_ml_model()
    
    # 3. è¼‰å…¥æ•¸æ“š
    logger.info("\n>>> è¼‰å…¥è‚¡ç¥¨æ•¸æ“š...")
    result = load_data()
    if result is None:
        logger.error("âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—")
        return
    df, latest_date = result
    
    # 4. æƒæä¸¦è©•åˆ†
    logger.info("\n>>> æƒæè‚¡ç¥¨è¨Šè™Ÿ...")
    signals, scan_date = scan_with_ml(df, model, feature_cols)
    
    # 5. ç”Ÿæˆå ±å‘Š
    logger.info("\n>>> ç”Ÿæˆ ML å ±å‘Š...")
    generate_ml_report(signals, scan_date, df_full=df)
    
    logger.info("\n" + "="*60)
    logger.info("æƒæå®Œæˆï¼")
    logger.info("="*60)

if __name__ == "__main__":
    main()
