#!/usr/bin/env python3
"""
Daily ML-Enhanced Stock Scanner

æ¯æ—¥æƒæç³»çµ±ï¼ŒåŒæ™‚è¼¸å‡º:
1. åŸå§‹ç­–ç•¥è¨Šè™Ÿ (HTF Trailing, CUP R=2.0)
2. ML å¢å¼·è¨Šè™Ÿ (ç¶“é ML 0.4 threshold éæ¿¾)
3. é€²å‡ºå ´é»ã€é¢¨éšªã€ML è©•åˆ†

Usage:
    python stock/ml_enhanced/daily_ml_scanner.py
    
Output:
    stock/ml_enhanced/daily_reports/YYYY-MM-DD/ml_daily_summary.md
    
Crontab:
    0 19 * * * cd /Users/sony/ml_stock && python stock/ml_enhanced/daily_ml_scanner.py
"""

import sys
import os
from datetime import datetime
import pandas as pd
import pickle

# Add paths
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from scripts.update_daily_data import main as update_data
from scripts.run_daily_scan import scan_latest_date, load_data
from src.strategies.htf import detect_htf
from src.strategies.cup import detect_cup
from src.strategies.vcp import detect_vcp

# Import shared modules
from src.utils.logger import setup_logger
from src.ml.features import extract_ml_features

# Configuration
MODEL_DIR = os.path.join(os.path.dirname(__file__), 'models')
FEATURE_INFO_PATH = os.path.join(MODEL_DIR, 'feature_info.pkl')
OUTPUT_BASE = os.path.join(os.path.dirname(__file__), 'daily_reports')
BACKTEST_RESULTS_PATH = os.path.join(os.path.dirname(__file__), 'results/ml_backtest_final.csv')

# Setup Logger
logger = setup_logger('daily_ml_scanner')

def load_all_ml_models():
    """è¼‰å…¥æ‰€æœ‰ ML æ¨¡å‹ (9å€‹: 3 patterns Ã— 3 exit modes)"""
    try:
        models = {}
        patterns = ['cup', 'htf', 'vcp']
        exit_modes = ['fixed_r2_t20', 'fixed_r3_t20', 'trailing_15r']
        
        for pat in patterns:
            for exit_mode in exit_modes:
                model_key = f'{pat}_{exit_mode}'
                model_path = os.path.join(MODEL_DIR, f'stock_selector_{model_key}.pkl')
                
                if os.path.exists(model_path):
                    with open(model_path, 'rb') as f:
                        models[model_key] = pickle.load(f)
                else:
                    logger.warning(f"âš ï¸ Model not found: {model_path}")
        
        # Load feature info
        with open(FEATURE_INFO_PATH, 'rb') as f:
            feature_info = pickle.load(f)
        
        logger.info(f"âœ… è¼‰å…¥ {len(models)} å€‹ ML æ¨¡å‹")
        return models, feature_info['feature_cols']
    except Exception as e:
        logger.error(f"âš ï¸ ML æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None, None

def load_backtest_results():
    """è¼‰å…¥å›æ¸¬çµæœ"""
    try:
        if not os.path.exists(BACKTEST_RESULTS_PATH):
            return None
        
        df = pd.read_csv(BACKTEST_RESULTS_PATH)
        return df
    except Exception as e:
        logger.error(f"âš ï¸ å›æ¸¬çµæœè¼‰å…¥å¤±æ•—: {e}")
        return None

def predict_best_exit(models, feature_cols, features_dict, pattern_type):
    """
    é æ¸¬æœ€ä½³å‡ºå ´ç­–ç•¥
    Returns: (best_exit_name, best_ml_score, all_predictions_dict)
    """
    if models is None:
        return 'fixed_r2_t20', 0.5, {}
    
    try:
        X = pd.DataFrame([features_dict])[feature_cols]
        
        # é æ¸¬æ‰€æœ‰3ç¨®å‡ºå ´æ–¹å¼
        exit_modes = ['fixed_r2_t20', 'fixed_r3_t20', 'trailing_15r']
        predictions = {}
        
        for exit_mode in exit_modes:
            model_key = f'{pattern_type}_{exit_mode}'
            if model_key in models:
                proba = models[model_key].predict_proba(X)[0][1]
                predictions[exit_mode] = proba
            else:
                predictions[exit_mode] = 0.5  # Fallback
        
        # æ‰¾å‡ºæœ€ä½³ç­–ç•¥
        best_exit = max(predictions.items(), key=lambda x: x[1])
        
        return best_exit[0], best_exit[1], predictions
        
    except Exception as e:
        logger.warning(f"    âš ï¸ ML é æ¸¬å¤±æ•—: {e}")
        return 'fixed_r2_t20', 0.5, {}

def scan_with_ml(df, model, feature_cols):
    """æƒæä¸¦æ·»åŠ  ML è©•åˆ†"""
    latest_date = df['date'].max()
    logger.info(f"\næƒææ—¥æœŸ: {latest_date}")
    
    latest_stocks = df[df['date'] == latest_date]['sid'].unique()
    logger.info(f"è‚¡ç¥¨æ•¸é‡: {len(latest_stocks)}")
    
    signals = []
    processed = 0
    
    for sid in latest_stocks:
        processed += 1
        if processed % 100 == 0:
            logger.info(f"å·²è™•ç† {processed}/{len(latest_stocks)} æª”è‚¡ç¥¨...")
        
        stock_df = df[df['sid'] == sid].reset_index(drop=True)
        n_rows = len(stock_df)
        
        if n_rows < 126:
            continue
        
        i = n_rows - 1
        window = stock_df.iloc[i - 126 + 1 : i + 1]
        row_today = stock_df.iloc[i]
        
        if row_today['date'] != latest_date:
            continue
        
        # MA info
        ma_info = {
            'ma50': row_today.get('ma50', 0),
            'ma150': row_today.get('ma150', 0),
            'ma200': row_today.get('ma200', 0),
            'low52': row_today.get('low52', 0)
        }
        
        rs_rating = row_today.get('rs_rating', 0)
        
        # Detect HTF
        is_htf, htf_buy, htf_stop, htf_grade = detect_htf(window, rs_rating=rs_rating)
        if is_htf and htf_buy and htf_stop and row_today['close'] > htf_stop:
            # Add temporary pattern info to row for feature extraction
            row_today_htf = row_today.copy()
            row_today_htf['htf_buy_price'] = htf_buy
            row_today_htf['htf_stop_price'] = htf_stop
            row_today_htf['htf_grade'] = htf_grade
            
            features = extract_ml_features(row_today_htf, 'htf')
            
            # é æ¸¬æœ€ä½³å‡ºå ´ç­–ç•¥
            best_exit, best_ml_score, all_preds = predict_best_exit(model, feature_cols, features, 'htf')
            
            # å‡ºå ´ç­–ç•¥åç¨±å°ç…§
            exit_names = {
                'fixed_r2_t20': 'Fixed R=2.0',
                'fixed_r3_t20': 'Fixed R=3.0',
                'trailing_15r': 'Trailing 1.5R'
            }
            
            signals.append({
                'date': latest_date,
                'sid': sid,
                'name': row_today['name'],
                'pattern': 'HTF',
                'buy_price': round(htf_buy, 2),
                'stop_price': round(htf_stop, 2),
                'risk_pct': round((htf_buy - htf_stop) / htf_buy * 100, 2),
                'grade': htf_grade if htf_grade else 'C',
                'current_price': round(row_today['close'], 2),
                'distance_pct': round((htf_buy - row_today['close']) / htf_buy * 100, 2),
                'ml_proba': round(best_ml_score, 3),
                'ml_selected': best_ml_score >= 0.4,
                'rs_rating': round(rs_rating, 1),
                'recommended_exit': exit_names.get(best_exit, best_exit),
                'exit_predictions': {
                    'r2': round(all_preds.get('fixed_r2_t20', 0), 2),
                    'r3': round(all_preds.get('fixed_r3_t20', 0), 2),
                    'trailing': round(all_preds.get('trailing_15r', 0), 2)
                }
            })
        
        # Detect CUP
        is_cup, cup_buy, cup_stop = detect_cup(window, ma_info, rs_rating=rs_rating)
        if is_cup and cup_buy and cup_stop and row_today['close'] > cup_stop:
            # Add temporary pattern info to row for feature extraction
            row_today_cup = row_today.copy()
            row_today_cup['cup_buy_price'] = cup_buy
            row_today_cup['cup_stop_price'] = cup_stop
            
            features = extract_ml_features(row_today_cup, 'cup')
            
            # é æ¸¬æœ€ä½³å‡ºå ´ç­–ç•¥
            best_exit, best_ml_score, all_preds = predict_best_exit(model, feature_cols, features, 'cup')
            
            exit_names = {
                'fixed_r2_t20': 'Fixed R=2.0',
                'fixed_r3_t20': 'Fixed R=3.0',
                'trailing_15r': 'Trailing 1.5R'
            }
            
            signals.append({
                'date': latest_date,
                'sid': sid,
                'name': row_today['name'],
                'pattern': 'CUP',
                'buy_price': round(cup_buy, 2),
                'stop_price': round(cup_stop, 2),
                'risk_pct': round((cup_buy - cup_stop) / cup_buy * 100, 2),
                'grade': 'N/A',
                'current_price': round(row_today['close'], 2),
                'distance_pct': round((cup_buy - row_today['close']) / cup_buy * 100, 2),
                'ml_proba': round(best_ml_score, 3),
                'ml_selected': best_ml_score >= 0.4,
                'rs_rating': round(rs_rating, 1),
                'recommended_exit': exit_names.get(best_exit, best_exit),
                'exit_predictions': {
                    'r2': round(all_preds.get('fixed_r2_t20', 0), 2),
                    'r3': round(all_preds.get('fixed_r3_t20', 0), 2),
                    'trailing': round(all_preds.get('trailing_15r', 0), 2)
                }
            })

        # Detect VCP
        vol_ma50 = window['volume'].rolling(50).mean().iloc[-1] if len(window) >= 50 else window['volume'].mean()
        is_vcp, vcp_buy, vcp_stop = detect_vcp(window, vol_ma50_val=vol_ma50, price_ma50_val=ma_info['ma50'], rs_rating=rs_rating)
        if is_vcp and vcp_buy and vcp_stop and row_today['close'] > vcp_stop:
            # Add temporary pattern info to row for feature extraction
            row_today_vcp = row_today.copy()
            row_today_vcp['vcp_buy_price'] = vcp_buy
            row_today_vcp['vcp_stop_price'] = vcp_stop
            
            features = extract_ml_features(row_today_vcp, 'vcp')
            
            # é æ¸¬æœ€ä½³å‡ºå ´ç­–ç•¥
            best_exit, best_ml_score, all_preds = predict_best_exit(model, feature_cols, features, 'vcp')
            
            exit_names = {
                'fixed_r2_t20': 'Fixed R=2.0',
                'fixed_r3_t20': 'Fixed R=3.0',
                'trailing_15r': 'Trailing 1.5R'
            }
            
            signals.append({
                'date': latest_date,
                'sid': sid,
                'name': row_today['name'],
                'pattern': 'VCP',
                'buy_price': round(vcp_buy, 2),
                'stop_price': round(vcp_stop, 2),
                'risk_pct': round((vcp_buy - vcp_stop) / vcp_buy * 100, 2),
                'grade': 'N/A',
                'current_price': round(row_today['close'], 2),
                'distance_pct': round((vcp_buy - row_today['close']) / vcp_buy * 100, 2),
                'ml_proba': round(best_ml_score, 3),
                'ml_selected': best_ml_score >= 0.4,
                'rs_rating': round(rs_rating, 1),
                'recommended_exit': exit_names.get(best_exit, best_exit),
                'exit_predictions': {
                    'r2': round(all_preds.get('fixed_r2_t20', 0), 2),
                    'r3': round(all_preds.get('fixed_r3_t20', 0), 2),
                    'trailing': round(all_preds.get('trailing_15r', 0), 2)
                }
            })
    
    total_signals = len(signals)
    ml_kept = sum(1 for s in signals if s['ml_selected'])
    logger.info(f"æƒæå®Œæˆ: ç¸½è¨Šè™Ÿ {total_signals}, MLâ‰¥0.4 {ml_kept}, è™•ç†è‚¡ç¥¨ {processed}")
    return signals, latest_date

def scan_past_week(df, model, feature_cols, latest_date):
    """æƒæéå»ä¸€é€±çš„è¨Šè™Ÿä¸¦åŠ ä¸Š ML è©•åˆ†"""
    from datetime import timedelta
    
    today = pd.to_datetime(latest_date)
    start_date = today - timedelta(days=7)
    
    # Filter for past 7 days (excluding today to avoid duplication if needed, but report separates them)
    # Actually report "Past Week" usually implies history excluding today, or including?
    # The original code used: df_week = df_full[pd.to_datetime(df_full['date']) >= start_date]
    # Let's keep it simple: Past 7 days excluding today for "Past Week" section
    
    mask = (pd.to_datetime(df['date']) >= start_date) & (pd.to_datetime(df['date']) < today)
    df_week = df[mask].copy()
    
    past_signals = []
    
    if df_week.empty:
        return past_signals
        
    # Iterate over patterns
    patterns = ['htf', 'cup', 'vcp']
    
    for pat in patterns:
        col_name = f'is_{pat}'
        if col_name not in df_week.columns:
            continue
            
        # Filter rows with this pattern
        pat_df = df_week[df_week[col_name] == True].copy()
        
        for _, row in pat_df.iterrows():
            # Basic validation
            buy_col = f'{pat}_buy_price'
            stop_col = f'{pat}_stop_price'
            
            if pd.isna(row.get(buy_col)) or pd.isna(row.get(stop_col)):
                continue
                
            # Extract features
            # Note: row must have necessary columns. extract_ml_features handles missing gracefully usually.
            # We need to ensure 'ma20', 'ma50' etc are present. load_data usually provides them.
            
            # Prepare row for feature extraction (needs specific format sometimes)
            # extract_ml_features expects the row to have specific pattern columns set if we pass pattern_type
            # It reads e.g. row['htf_buy_price'] which exists.
            
            features = extract_ml_features(row, pat)
            
            # é æ¸¬æœ€ä½³å‡ºå ´ç­–ç•¥
            best_exit, ml_proba, all_preds = predict_best_exit(models, feature_cols, features, pat)
            
            # Only keep if ML score is decent (e.g. >= 0.4) to show "High Quality" past signals
            if ml_proba >= 0.4:
                exit_names = {
                    'fixed_r2_t20': 'R=2.0',
                    'fixed_r3_t20': 'R=3.0',
                    'trailing_15r': 'Trail'
                }
                
                past_signals.append({
                    'date': pd.to_datetime(row['date']).strftime('%Y-%m-%d'),
                    'sid': row['sid'],
                    'name': row.get('name', ''),
                    'pattern': pat.upper(),
                    'buy_price': round(row[buy_col], 2),
                    'stop_price': round(row[stop_col], 2),
                    'ml_proba': round(ml_proba, 3),
                    'grade': row.get(f'{pat}_grade', 'N/A'),
                    'recommended_exit': exit_names.get(best_exit, best_exit),
                    'exit_predictions': {
                        'r2': round(all_preds.get('fixed_r2_t20', 0), 2),
                        'r3': round(all_preds.get('fixed_r3_t20', 0), 2),
                        'trailing': round(all_preds.get('trailing_15r', 0), 2)
                    }
                })
    
    return past_signals

def generate_ml_report(signals, scan_date, df_full=None, past_signals=None):
    """ç”Ÿæˆ ML å¢å¼·å ±å‘Šï¼ˆå³ä½¿ä»Šæ—¥ç„¡è¨Šè™Ÿä¹Ÿç”Ÿæˆï¼‰"""
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    today_str = datetime.now().strftime('%Y-%m-%d')
    output_dir = os.path.join(OUTPUT_BASE, today_str)
    os.makedirs(output_dir, exist_ok=True)
    
    # è™•ç†è¨Šè™Ÿæ•¸æ“š
    if signals:
        df_signals = pd.DataFrame(signals)
        # åˆ†é›¢ ML é¸ä¸­å’Œæœªé¸ä¸­
        ml_selected = df_signals[df_signals['ml_selected'] == True]
        ml_rejected = df_signals[df_signals['ml_selected'] == False]
    else:
        df_signals = pd.DataFrame()
        ml_selected = pd.DataFrame()
        ml_rejected = pd.DataFrame()
    
    # ç”Ÿæˆå ±å‘Š
    report_path = os.path.join(output_dir, 'ml_daily_summary.md')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"# ML-Enhanced è‚¡ç¥¨è¨Šè™Ÿå ±å‘Š\n")
        f.write(f"**æƒææ—¥æœŸ**: {scan_date}\n")
        f.write(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        # çµ±è¨ˆæ‘˜è¦
        f.write(f"## ğŸ“Š æœ¬æ—¥è¨Šè™Ÿçµ±è¨ˆ\n\n")
        
        if not df_signals.empty:
            f.write(f"- **ç¸½è¨Šè™Ÿæ•¸**: {len(df_signals)}\n")
            f.write(f"- **ML æ¨è–¦**: {len(ml_selected)} (é«˜å“è³ª)\n")
            f.write(f"- **åŸå§‹è¨Šè™Ÿ**: {len(ml_rejected)} (åƒè€ƒ)\n\n")
        else:
            f.write(f"- **ç¸½è¨Šè™Ÿæ•¸**: 0\n\n")
            f.write("**æœ¬æ—¥ç„¡ç¬¦åˆæ¢ä»¶çš„å‹æ…‹è¨Šè™Ÿã€‚**\n\n")
        
        f.write("---\n\n")
        
        # ML æ¨è–¦è¨Šè™Ÿ
        if not ml_selected.empty:
            f.write(f"## âœ… ML æ¨è–¦è¨Šè™Ÿ ({len(ml_selected)} æª”)\n\n")
            f.write("> **ML æ©Ÿç‡ â‰¥ 0.4**ï¼šé«˜å“è³ªè¨Šè™Ÿï¼Œå»ºè­°å„ªå…ˆç ”ç©¶\n\n")
            
            # HTF æ¨è–¦
            htf_ml = ml_selected[ml_selected['pattern'] == 'HTF'].sort_values('ml_proba', ascending=False)
            if not htf_ml.empty:
                f.write(f"### ğŸš€ HTF å‹æ…‹ ({len(htf_ml)} æª”)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | è‚¡ç¥¨åç¨± | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | è·é›¢% | Grade | **æ¨è–¦å‡ºå ´** | MLåˆ†æ•¸ | å…¶ä»–é¸é … |\n")
                f.write("|---------|---------|--------|--------|--------|-------|-------|------------|--------|----------|\n")
                for _, row in htf_ml.iterrows():
                    other_opts = f"R2:{row['exit_predictions']['r2']}, R3:{row['exit_predictions']['r3']}, Trail:{row['exit_predictions']['trailing']}"
                    f.write(f"| **{row['sid']}** | {row['name']} | {row['current_price']} | ")
                    f.write(f"{row['buy_price']} | {row['stop_price']} | {row['distance_pct']}% | ")
                    f.write(f"{row['grade']} | **{row['recommended_exit']}** â­ | **{row['ml_proba']}** | {other_opts} |\n")
                f.write("\n")
            
            # CUP æ¨è–¦
            cup_ml = ml_selected[ml_selected['pattern'] == 'CUP'].sort_values('ml_proba', ascending=False)
            if not cup_ml.empty:
                f.write(f"### ğŸ† CUP å‹æ…‹ ({len(cup_ml)} æª”)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | è‚¡ç¥¨åç¨± | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | è·é›¢% | **æ¨è–¦å‡ºå ´** | MLåˆ†æ•¸ | å…¶ä»–é¸é … |\n")
                f.write("|---------|---------|--------|--------|--------|-------|------------|--------|----------|\n")
                for _, row in cup_ml.iterrows():
                    other_opts = f"R2:{row['exit_predictions']['r2']}, R3:{row['exit_predictions']['r3']}, Trail:{row['exit_predictions']['trailing']}"
                    f.write(f"| **{row['sid']}** | {row['name']} | {row['current_price']} | ")
                    f.write(f"{row['buy_price']} | {row['stop_price']} | {row['distance_pct']}% | ")
                    f.write(f"**{row['recommended_exit']}** â­ | **{row['ml_proba']}** | {other_opts} |\n")
                f.write("\n")

            # VCP æ¨è–¦
            vcp_ml = ml_selected[ml_selected['pattern'] == 'VCP'].sort_values('ml_proba', ascending=False)
            if not vcp_ml.empty:
                f.write(f"### ğŸŒ€ VCP å‹æ…‹ ({len(vcp_ml)} æª”)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | è‚¡ç¥¨åç¨± | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | è·é›¢% | **æ¨è–¦å‡ºå ´** | MLåˆ†æ•¸ | å…¶ä»–é¸é … |\n")
                f.write("|---------|---------|--------|--------|--------|-------|------------|--------|----------|\n")
                for _, row in vcp_ml.iterrows():
                    other_opts = f"R2:{row['exit_predictions']['r2']}, R3:{row['exit_predictions']['r3']}, Trail:{row['exit_predictions']['trailing']}"
                    f.write(f"| **{row['sid']}** | {row['name']} | {row['current_price']} | ")
                    f.write(f"{row['buy_price']} | {row['stop_price']} | {row['distance_pct']}% | ")
                    f.write(f"**{row['recommended_exit']}** â­ | **{row['ml_proba']}** | {other_opts} |\n")
                f.write("\n")
            
            f.write("---\n\n")
        
        # åŸå§‹è¨Šè™Ÿï¼ˆæœªè¢« ML é¸ä¸­ï¼‰
        if not ml_rejected.empty:
            f.write(f"## ğŸ“‹ å…¶ä»–åŸå§‹è¨Šè™Ÿ ({len(ml_rejected)} æª”)\n\n")
            f.write("> **ML æ©Ÿç‡ < 0.4**ï¼šå“è³ªè¼ƒä½ï¼Œåƒ…ä¾›åƒè€ƒ\n\n")
            
            # HTF å…¶ä»–
            htf_other = ml_rejected[ml_rejected['pattern'] == 'HTF'].sort_values('ml_proba', ascending=False)
            if not htf_other.empty:
                f.write(f"### HTF å‹æ…‹ ({len(htf_other)} æª”)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | Grade | MLåˆ†æ•¸ |\n")
                f.write("|---------|--------|--------|--------|-------|--------|\n")
                for _, row in htf_other.iterrows():
                    f.write(f"| {row['sid']} | {row['current_price']} | {row['buy_price']} | ")
                    f.write(f"{row['stop_price']} | {row['grade']} | {row['ml_proba']} |\n")
                f.write("\n")
            
            # CUP å…¶ä»–
            cup_other = ml_rejected[ml_rejected['pattern'] == 'CUP'].sort_values('ml_proba', ascending=False)
            if not cup_other.empty:
                f.write(f"### CUP å‹æ…‹ ({len(cup_other)} æª”)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | MLåˆ†æ•¸ |\n")
                f.write("|---------|--------|--------|--------|--------|\n")
                for _, row in cup_other.iterrows():
                    f.write(f"| {row['sid']} | {row['current_price']} | {row['buy_price']} | ")
                    f.write(f"{row['stop_price']} | {row['ml_proba']} |\n")
                f.write("\n")

            # VCP å…¶ä»–
            vcp_other = ml_rejected[ml_rejected['pattern'] == 'VCP'].sort_values('ml_proba', ascending=False)
            if not vcp_other.empty:
                f.write(f"### VCP å‹æ…‹ ({len(vcp_other)} æª”)\n\n")
                f.write("| è‚¡ç¥¨ä»£è™Ÿ | ç•¶å‰åƒ¹ | è²·å…¥åƒ¹ | åœæåƒ¹ | MLåˆ†æ•¸ |\n")
                f.write("|---------|--------|--------|--------|--------|\n")
                for _, row in vcp_other.iterrows():
                    f.write(f"| {row['sid']} | {row['current_price']} | {row['buy_price']} | ")
                    f.write(f"{row['stop_price']} | {row['ml_proba']} |\n")
                f.write("\n")
        
        f.write("---\n\n")
        
        # éå»ä¸€é€±è¨Šè™Ÿå½™æ•´ (ML Enhanced)
        f.write("## ğŸ“… éå»ä¸€é€±è¨Šè™Ÿå½™æ•´ (ML Enhanced)\n\n")
        if past_signals:
            f.write("> åƒ…é¡¯ç¤º ML åˆ†æ•¸ â‰¥ 0.4 çš„é«˜å“è³ªæ­·å²è¨Šè™Ÿ\n\n")
            
            df_past = pd.DataFrame(past_signals)
            
            # HTF
            htf_past = df_past[df_past['pattern'] == 'HTF'].sort_values(['date', 'ml_proba'], ascending=[False, False])
            if not htf_past.empty:
                f.write(f"### ğŸš€ HTF ({len(htf_past)} æª”)\n\n")
                f.write("| æ—¥æœŸ | è‚¡ç¥¨ä»£è™Ÿ | è²·å…¥åƒ¹ | åœæåƒ¹ | Grade | MLåˆ†æ•¸ |\n")
                f.write("|------|---------|--------|--------|-------|--------|\n")
                for _, row in htf_past.iterrows():
                    f.write(f"| {row['date']} | {row['sid']} | {row['buy_price']} | {row['stop_price']} | {row['grade']} | **{row['ml_proba']}** |\n")
                f.write("\n")
            
            # CUP
            cup_past = df_past[df_past['pattern'] == 'CUP'].sort_values(['date', 'ml_proba'], ascending=[False, False])
            if not cup_past.empty:
                f.write(f"### ğŸ† CUP ({len(cup_past)} æª”)\n\n")
                f.write("| æ—¥æœŸ | è‚¡ç¥¨ä»£è™Ÿ | è²·å…¥åƒ¹ | åœæåƒ¹ | MLåˆ†æ•¸ |\n")
                f.write("|------|---------|--------|--------|--------|\n")
                for _, row in cup_past.iterrows():
                    f.write(f"| {row['date']} | {row['sid']} | {row['buy_price']} | {row['stop_price']} | **{row['ml_proba']}** |\n")
                f.write("\n")
                
            # VCP
            vcp_past = df_past[df_past['pattern'] == 'VCP'].sort_values(['date', 'ml_proba'], ascending=[False, False])
            if not vcp_past.empty:
                f.write(f"### ğŸŒ€ VCP ({len(vcp_past)} æª”)\n\n")
                f.write("| æ—¥æœŸ | è‚¡ç¥¨ä»£è™Ÿ | è²·å…¥åƒ¹ | åœæåƒ¹ | MLåˆ†æ•¸ |\n")
                f.write("|------|---------|--------|--------|--------|\n")
                for _, row in vcp_past.iterrows():
                    f.write(f"| {row['date']} | {row['sid']} | {row['buy_price']} | {row['stop_price']} | **{row['ml_proba']}** |\n")
                f.write("\n")
                
        else:
            f.write("éå»ä¸€é€±ç„¡ ML â‰¥ 0.4 çš„é«˜å“è³ªè¨Šè™Ÿã€‚\n\n")
            
        f.write("---\n\n")
        
        # Top Strategies (Dynamic)
        backtest_df = load_backtest_results()
        if backtest_df is not None and not backtest_df.empty:
            f.write("## ğŸ† Top 3 Strategies (ML-Enhanced)\n\n")
            
            # Sort by Annual Return
            top_strategies = backtest_df.sort_values('Ann. Return %', ascending=False).head(3)
            
            f.write("### ä¾å¹´åŒ–å ±é…¬æ’åº\n\n")
            for i, (_, row) in enumerate(top_strategies.iterrows(), 1):
                strategy_name = row['Strategy']
                ann_ret = row['Ann. Return %']
                sharpe = row['Sharpe']
                avg_hold = row.get('Avg Holding Days', 'N/A')
                max_win = row.get('Max Win Streak', 'N/A')
                max_loss = row.get('Max Loss Streak', 'N/A')
                mdd = row.get('Max DD %', 'N/A')
                win_rate = row.get('Win Rate', 'N/A')
                
                f.write(f"{i}. **{strategy_name}**\n")
                f.write(f"   - å¹´åŒ–å ±é…¬: **{ann_ret}%**, Sharpe: **{sharpe}**, å‹ç‡: {win_rate}%\n")
                f.write(f"   - å¹³å‡æŒå€‰: {avg_hold} å¤©, MDD: {mdd}%\n")
                f.write(f"   - é€£å‹/é€£æ•—: {max_win} / {max_loss}\n\n")

            # Sort by Sharpe
            top_sharpe = backtest_df.sort_values('Sharpe', ascending=False).head(3)
            f.write("### ä¾ Sharpe æ’åº\n\n")
            for i, (_, row) in enumerate(top_sharpe.iterrows(), 1):
                strategy_name = row['Strategy']
                ann_ret = row['Ann. Return %']
                sharpe = row['Sharpe']
                avg_hold = row.get('Avg Holding Days', 'N/A')
                max_win = row.get('Max Win Streak', 'N/A')
                max_loss = row.get('Max Loss Streak', 'N/A')
                mdd = row.get('Max DD %', 'N/A')
                win_rate = row.get('Win Rate', 'N/A')
                
                f.write(f"{i}. **{strategy_name}**\n")
                f.write(f"   - Sharpe: **{sharpe}**, å¹´åŒ–å ±é…¬: **{ann_ret}%**, å‹ç‡: {win_rate}%\n")
                f.write(f"   - å¹³å‡æŒå€‰: {avg_hold} å¤©, MDD: {mdd}%\n")
                f.write(f"   - é€£å‹/é€£æ•—: {max_win} / {max_loss}\n\n")
            
            f.write("---\n\n")
        else:
            # Fallback if no backtest results
            f.write("## ğŸ† Top 3 Strategies (ML-Enhanced)\n\n")
            f.write("> âš ï¸ ç„¡æ³•è¼‰å…¥æœ€æ–°å›æ¸¬çµæœï¼Œè«‹æª¢æŸ¥ ml_backtest_final.csv\n\n")
            f.write("---\n\n")
        
        # äº¤æ˜“ç­–ç•¥èªªæ˜ (å¾å›æ¸¬çµæœå‹•æ…‹ç”Ÿæˆ)
        f.write("## ğŸ“– äº¤æ˜“ç­–ç•¥èªªæ˜\n\n")
        
        # å¾å›æ¸¬çµæœä¸­æ‰¾å‡ºæœ€ä½³ç­–ç•¥
        if backtest_df is not None and not backtest_df.empty:
            # HTF æœ€ä½³ç­–ç•¥
            htf_best = backtest_df[
                (backtest_df['Strategy'].str.contains('HTF Fixed')) &
                (backtest_df['ml_threshold'].notna())
            ].nlargest(1, 'Ann. Return %')
            
            if not htf_best.empty:
                htf_row = htf_best.iloc[0]
                f.write(f"### HTF Fixed Exit (ML æ¨è–¦) â­\n")
                f.write(f"- **é€²å ´**: åƒ¹æ ¼çªç ´è²·å…¥åƒ¹\n")
                f.write(f"- **å‡ºå ´**: **å›ºå®š 2R åœåˆ©** æˆ– 20 å¤©æ™‚é–“å‡ºå ´\n")
                f.write(f"- **é æœŸ**: {htf_row['Ann. Return %']:.1f}% å¹´åŒ–å ±é…¬, ")
                f.write(f"Sharpe {htf_row['Sharpe']:.2f}, å‹ç‡ {htf_row['Win Rate']:.1f}%\n")
                f.write(f"- **MLé–¾å€¼**: {htf_row['ml_threshold']}, äº¤æ˜“æ¬¡æ•¸: {int(htf_row['Trades'])}\n\n")
            
            # CUP æœ€ä½³ç­–ç•¥
            cup_best = backtest_df[
                (backtest_df['Strategy'].str.contains('CUP Fixed')) &
                (backtest_df['ml_threshold'].notna())
            ].nlargest(1, 'Ann. Return %')
            
            if not cup_best.empty:
                cup_row = cup_best.iloc[0]
                # åˆ¤æ–·æ˜¯ R=2.0 é‚„æ˜¯ R=3.0
                r_value = "3R" if "R=3.0" in cup_row['Strategy'] else "2R"
                f.write(f"### CUP Fixed Exit (ML æ¨è–¦) â­\n")
                f.write(f"- **é€²å ´**: åƒ¹æ ¼çªç ´è²·å…¥åƒ¹\n")
                f.write(f"- **å‡ºå ´**: **å›ºå®š {r_value} åœåˆ©** æˆ– 20 å¤©æ™‚é–“å‡ºå ´\n")
                f.write(f"- **é æœŸ**: {cup_row['Ann. Return %']:.1f}% å¹´åŒ–å ±é…¬, ")
                f.write(f"Sharpe {cup_row['Sharpe']:.2f}, å‹ç‡ {cup_row['Win Rate']:.1f}%\n")
                f.write(f"- **MLé–¾å€¼**: {cup_row['ml_threshold']}, äº¤æ˜“æ¬¡æ•¸: {int(cup_row['Trades'])}\n\n")
        else:
            # Fallback to hardcoded if backtest data not available
            f.write("### HTF Fixed Exit (ML æ¨è–¦) â­\n")
            f.write("- **é€²å ´**: åƒ¹æ ¼çªç ´è²·å…¥åƒ¹\n")
            f.write("- **å‡ºå ´**: **å›ºå®š 2R åœåˆ©** æˆ– 20 å¤©æ™‚é–“å‡ºå ´\n")
            f.write("- **é æœŸ**: ä½¿ç”¨æœ€æ–°å›æ¸¬æ•¸æ“š (è«‹åŸ·è¡Œ weekly_retrain.py)\n\n")
            f.write("### CUP Fixed Exit (ML æ¨è–¦) â­\n")
            f.write("- **é€²å ´**: åƒ¹æ ¼çªç ´è²·å…¥åƒ¹\n")
            f.write("- **å‡ºå ´**: **å›ºå®š 3R åœåˆ©** æˆ– 20 å¤©æ™‚é–“å‡ºå ´\n")
            f.write("- **é æœŸ**: ä½¿ç”¨æœ€æ–°å›æ¸¬æ•¸æ“š (è«‹åŸ·è¡Œ weekly_retrain.py)\n\n")
        
        f.write("### ML åˆ†æ•¸è§£è®€\n\n")
        
        # å¾å›æ¸¬æ•¸æ“šå‹•æ…‹ç”Ÿæˆ ML åˆ†æ•¸è§£è®€
        if backtest_df is not None and not backtest_df.empty:
            # æ‰¾å‡ºå„ ML é–¾å€¼çš„æœ€ä½³ Sharpe
            ml_05 = backtest_df[backtest_df['ml_threshold'] == 0.5]['Sharpe'].max()
            ml_04 = backtest_df[backtest_df['ml_threshold'] == 0.4]['Sharpe'].max()
            ml_03 = backtest_df[backtest_df['ml_threshold'] == 0.3]['Sharpe'].max()
            
            f.write(f"- **â‰¥ 0.5**: **Elite (é ‚ç´š)** - æ­·å²å›æ¸¬æœ€ä½³ Sharpe {ml_05:.2f}ï¼Œæ¥µé«˜å‹ç‡ â­\n")
            f.write(f"- **0.4-0.5**: **Strong (å¼·åŠ›)** - æ­·å²å›æ¸¬æœ€ä½³ Sharpe {ml_04:.2f}ï¼Œé©åˆæ¨™æº–æ“ä½œ\n")
            f.write(f"- **0.3-0.4**: **Moderate (æ™®é€š)** - æ­·å²å›æ¸¬æœ€ä½³ Sharpe {ml_03:.2f}ï¼Œåƒ…ä¾›è§€å¯Ÿ\n\n")
        else:
            # Fallback
            f.write("- **â‰¥ 0.5**: **Elite (é ‚ç´š)** - é«˜å“è³ªè¨Šè™Ÿ â­\n")
            f.write("- **0.4-0.5**: **Strong (å¼·åŠ›)** - é©åˆæ¨™æº–æ“ä½œ\n")
            f.write("- **0.3-0.4**: **Moderate (æ™®é€š)** - åƒ…ä¾›è§€å¯Ÿ\n\n")
    
    # å„²å­˜ CSV (å³ä½¿æ˜¯ç©ºçš„ä¹Ÿå„²å­˜)
    csv_path = os.path.join(output_dir, 'ml_signals.csv')
    if not df_signals.empty:
        df_signals.to_csv(csv_path, index=False)
    else:
        # å‰µå»ºç©º CSV
        pd.DataFrame(columns=['date', 'sid', 'name', 'pattern', 'buy_price', 'stop_price', 
                              'risk_pct', 'grade', 'current_price', 'distance_pct', 
                              'ml_proba', 'ml_selected', 'rs_rating']).to_csv(csv_path, index=False)
    
    logger.info(f"\nâœ… ML å ±å‘Šå·²å„²å­˜è‡³: {report_path}")
    logger.info(f"âœ… CSV å·²å„²å­˜è‡³: {csv_path}")
    
    # é¡¯ç¤ºæ‘˜è¦
    logger.info(f"\n{'='*60}")
    logger.info(f"ML æ¨è–¦è¨Šè™Ÿçµ±è¨ˆ")
    logger.info(f"{'='*60}")
    if not df_signals.empty:
        logger.info(f"HTF (ML â‰¥ 0.4): {len(ml_selected[ml_selected['pattern'] == 'HTF'])} æª”")
        logger.info(f"CUP (ML â‰¥ 0.4): {len(ml_selected[ml_selected['pattern'] == 'CUP'])} æª”")
        logger.info(f"VCP (ML â‰¥ 0.4): {len(ml_selected[ml_selected['pattern'] == 'VCP'])} æª”")
        logger.info(f"ç¸½è¨ˆæ¨è–¦: {len(ml_selected)} æª”")
    else:
        logger.info(f"æœ¬æ—¥ç„¡è¨Šè™Ÿ")

def main():
    logger.info("="*60)
    logger.info("ML-Enhanced Daily Stock Scanner")
    logger.info("="*60)
    
    # 1. æ›´æ–°æ•¸æ“š
    logger.info("\n>>> æ›´æ–°æ¯æ—¥æ•¸æ“š...")
    try:
        update_data()
    except Exception as e:
        logger.error(f"âš ï¸ æ•¸æ“šæ›´æ–°å¤±æ•—: {e}")
    
    # 2. è¼‰å…¥ ML æ¨¡å‹
    logger.info("\n>>> è¼‰å…¥ ML æ¨¡å‹...")
    models, feature_cols = load_all_ml_models()
    if models is None or feature_cols is None:
        logger.error("âŒ æ¨¡å‹æˆ–ç‰¹å¾µåˆ—è¡¨è¼‰å…¥å¤±æ•—ï¼Œåœæ­¢æµç¨‹ã€‚")
        return
    
    # 3. è¼‰å…¥æ•¸æ“š
    logger.info("\n>>> è¼‰å…¥è‚¡ç¥¨æ•¸æ“š...")
    result = load_data()
    if result is None:
        logger.error("âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—")
        return
    df, latest_date = result
    logger.info(f"æ•¸æ“šè¼‰å…¥å®Œæˆ: {len(df)} ç­†ï¼Œè‚¡ç¥¨ {df['sid'].nunique()} æª”ï¼Œæœ€æ–°æ—¥æœŸ {latest_date}")
    
    # 4. æƒæä¸¦è©•åˆ†
    logger.info("\n>>> æƒæè‚¡ç¥¨è¨Šè™Ÿ (ä»Šæ—¥)...")
    signals, scan_date = scan_with_ml(df, models, feature_cols)
    
    logger.info("\n>>> æƒæè‚¡ç¥¨è¨Šè™Ÿ (éå»ä¸€é€±)...")
    past_signals = scan_past_week(df, models, feature_cols, latest_date)
    logger.info(f"éå»ä¸€é€±é«˜å“è³ªè¨Šè™Ÿ (ML>=0.4): {len(past_signals)} æª”")
    
    # 5. ç”Ÿæˆå ±å‘Š
    logger.info("\n>>> ç”Ÿæˆ ML å ±å‘Š...")
    generate_ml_report(signals, scan_date, df_full=df, past_signals=past_signals)
    
    logger.info("\n" + "="*60)
    logger.info("æƒæå®Œæˆï¼")
    logger.info("="*60)

if __name__ == "__main__":
    main()
